<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>OpenCV on Jifan&#39;s Blog</title>
    <link>https://jifan.tech/tags/opencv/</link>
    <description>Recent content in OpenCV on Jifan&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 May 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://jifan.tech/tags/opencv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenCV 源码分析：SIFT 算法及原理简介</title>
      <link>https://jifan.tech/posts/2019-05-10/opencv-4/</link>
      <pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jifan.tech/posts/2019-05-10/opencv-4/</guid>
      <description>本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。
 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:
 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：
1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。
Koenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \sigma)$，它是由可变尺度高斯函数 $G(x, y, \sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：</description>
    </item>
    
    <item>
      <title>OpenCV 相机检校：原理及简单实现</title>
      <link>https://jifan.tech/posts/2019-04-18/opencv-3/</link>
      <pubDate>Thu, 18 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jifan.tech/posts/2019-04-18/opencv-3/</guid>
      <description>本文主要参考自 OpenCV 官方教程 OpenCV: Camera calibration With OpenCV，大部分内容是对原文的直接翻译。
 1. 前言 利用手机相机对棋盘图拍摄得到的图像如下（左边为原图，右边为二值化处理后的图像）：
如下所示，将其与原始棋盘图对比（左侧为原始图像，右侧为手机相机拍摄影像）。可以明显地看出出现了一定程度的畸变。
2. 相机检校原理 目前常用的相机检校方法是附加参数法，其关键在于通过一组额外参数拟合镜头畸变，主要是径向畸变和切向畸变：
$$ \begin{align} dx &amp;amp;= x(k_1r^2+k_2r^4+k_3r^6) + p_1(r^2+2x^2) + p_2xy \ dy &amp;amp;= \underbrace{y(k_1r^2+k_2r^4+k_3r^6)}\text{radial distortion} + \underbrace{p_2(r^2+2y^2) + p_1xy}\text{tangential distortion} \end{align} $$
式中，
$$ x=x&amp;rsquo;-x_0, \quad y=y&amp;rsquo;-y_0 \ r^2 = x^2 + y^2 $$
其中 $(x&amp;rsquo;,y&amp;rsquo;)$ 为像片坐标的原始量测值，$k_i,(i=1,2,3)$ 为径向畸变参数，$p_j, (j=1,2)$ 为切向畸变参数。所以 5 个畸变参数构成的矩阵为：
$$ distortion_coeffients = (\begin{matrix}k_1&amp;amp;k_2&amp;amp;p_1&amp;amp;p_2&amp;amp;k_3\end{matrix}) $$
对于影像坐标和物空间坐标的转换关系为：
$$ \begin{bmatrix}x\y\f\end{bmatrix}= K \begin{bmatrix}X\Y\Z\end{bmatrix}= \begin{bmatrix}f_x&amp;amp;0&amp;amp;c_x\0&amp;amp;f_y&amp;amp;c_y\0&amp;amp;0&amp;amp;1\end{bmatrix} \begin{bmatrix}X\Y\Z\end{bmatrix} $$</description>
    </item>
    
    <item>
      <title>OpenCV 点特征提取算子：Moravec，Forstner 与 Harris</title>
      <link>https://jifan.tech/posts/2019-04-02/opencv-2/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jifan.tech/posts/2019-04-02/opencv-2/</guid>
      <description>在计算机视觉（Computer Vision）与摄影测量（Photogrammetry）中，我们在不同影像之间找到相匹配的特征，已建立两幅影像之间的联系，提取出我们所需要的信息。这些特征主要分为：
 边缘（Edges） 角点（Corners） 兴趣区域 ROI（Regions of Interest）  其中，提取点特征的算子称为兴趣算子或有利算子（Interest Operator），即运用某种算法从影像种提取我们感兴趣的、有利于某种目的的点。
人眼对角点的识别通常是在一个局部的小区域或小窗口内完成的。如果在各个方向上移动这个特征的小窗口，窗口内区域的灰度发生了较大的变化，那么就认为在窗口内遇到了角点。如果这个特定的窗口在图像各个方面移动时，窗口内图像的灰度没有发生变化，那么窗口内就不存在角点；如果窗口在某一个方向移动时，窗口内图像的灰度发生了较大的变化，而在另一些方向上没有发生变化，那么窗口内的图像可能只是一条直线的线段。
角点的特殊之处在于，它是两条边的交点，所以它代表这两条边的方向发生变化的点。因此，图像在该点的梯度（在各个方向上）具有明显的变化。利用这一点，前人提出了一系列算法，其中比较经典的有 Moravec 算子、Forstner 算子以及 Harris 算子等。
Moravec 算子 基本原理 Moravec 于 1977 年提出利用灰度方差提取点特征的算子，其步骤为：
1. 计算各像元的兴趣值 $IV$（Interest Value）。 在以像素 $(c, r)$ 为中心的 $w \times w$ 的窗口中（如 $5 \times 5$ 的窗口），计算四个方向相邻像素灰度差的平方和：
$$ \begin{cases} V_1 &amp;amp;=&amp;amp; \sum_{i = -k}^{k-1}(g_{c+i,r}-g_{c+i+1, r})^2 \[2ex] V_2 &amp;amp;=&amp;amp; \sum_{i = -k}^{k-1}(g_{c+i,r+i}-g_{c+i+1, r+i+1})^2 \[2ex] V_3 &amp;amp;=&amp;amp; \sum_{i = -k}^{k-1}(g_{c,r+i}-g_{c+i+1, r+i+1})^2 \[2ex] V_4 &amp;amp;=&amp;amp; \sum_{i = -k}^{k-1}(g_{c+i,r-i}-g_{c+i+1, r-i-1})^2 \end{cases} $$</description>
    </item>
    
    <item>
      <title>OpenCV 内置边缘检测算子：Canny，Sobel 与 Laplace</title>
      <link>https://jifan.tech/posts/2019-03-19/opencv-1/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jifan.tech/posts/2019-03-19/opencv-1/</guid>
      <description>边缘检测（Edge Detection）是图像处理的基础内容。本文中，我从OpenCV官网上下载了最新版本的 OpenCV 4.0.1（2018-12-22），借助官方文档和网络教程完成了环境配置与测试，具体步骤不再赘述。
在 OpenCV 中可用于边缘检测的算子主要有：
 Canny 算子 Sobel 算子 Laplace 算子  Canny 算子 理论 Canny 算法是由 John F. Canny 于 1987 年在 A computational approach to edge detection 一文提出来的，它旨在满足三个主要标准：
 低错误率 (Low error rate)：意味着只检测实际存在的边缘。 高定位性 (Good localization)：将检测到的边缘像素与实际边缘像素之间的距离最小化。 最小响应 (Minimal response)：每个边缘只有一个检测器响应。  Canny 算子的步骤如下：
 滤掉任何噪声。这一过程将使用高斯滤波器。例如，一个 5×5 的高斯内核如下所示：  $$ K = \dfrac{1}{159}\begin{bmatrix} 2 &amp;amp; 4 &amp;amp; 5 &amp;amp; 4 &amp;amp; 2 \ 4 &amp;amp; 9 &amp;amp; 12 &amp;amp; 9 &amp;amp; 4 \ 5 &amp;amp; 12 &amp;amp; 15 &amp;amp; 12 &amp;amp; 5 \ 4 &amp;amp; 9 &amp;amp; 12 &amp;amp; 9 &amp;amp; 4 \ 2 &amp;amp; 4 &amp;amp; 5 &amp;amp; 4 &amp;amp; 2 \end{bmatrix} $$</description>
    </item>
    
  </channel>
</rss>
