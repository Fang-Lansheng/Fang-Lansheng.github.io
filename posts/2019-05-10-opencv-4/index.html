<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>OpenCV 源码分析：SIFT 算法原理与实现 | Jifan&#39;s Blog</title>
<meta name="keywords" content="OpenCV, C&#43;&#43;" />
<meta name="description" content="本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。
 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:
 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：
1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。
Koenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \sigma)$，它是由可变尺度高斯函数 $G(x, y, \sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：">
<meta name="author" content="Jifan">
<link rel="canonical" href="https://jifan.tech/posts/2019-05-10-opencv-4/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css" integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://jifan.tech/imgs/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://jifan.tech/imgs/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://jifan.tech/imgs/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://jifan.tech/imgs/apple-touch-icon.png">
<link rel="mask-icon" href="https://jifan.tech/imgs/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="OpenCV 源码分析：SIFT 算法原理与实现" />
<meta property="og:description" content="本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。
 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:
 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：
1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。
Koenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \sigma)$，它是由可变尺度高斯函数 $G(x, y, \sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jifan.tech/posts/2019-05-10-opencv-4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-10T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2019-05-10T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="OpenCV 源码分析：SIFT 算法原理与实现"/>
<meta name="twitter:description" content="本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。
 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:
 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：
1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。
Koenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \sigma)$，它是由可变尺度高斯函数 $G(x, y, \sigma)$ 与输入图像 $I(x,y)$ 卷积得到的："/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://jifan.tech/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "OpenCV 源码分析：SIFT 算法原理与实现",
      "item": "https://jifan.tech/posts/2019-05-10-opencv-4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "OpenCV 源码分析：SIFT 算法原理与实现",
  "name": "OpenCV 源码分析：SIFT 算法原理与实现",
  "description": "本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。\n 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:\n 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：\n1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。\nKoenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \\sigma)$，它是由可变尺度高斯函数 $G(x, y, \\sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：",
  "keywords": [
    "OpenCV", "C++"
  ],
  "articleBody": " 本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。\n 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:\n 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：\n1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。\nKoenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \\sigma)$，它是由可变尺度高斯函数 $G(x, y, \\sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：\n$$ \\begin{equation*} L(x, y, \\sigma) = G(x, y, \\sigma) \\bigotimes I(x, y) % \\label{eq:scale-space} \\end{equation*} $$\n其中，$\\bigotimes$ 表示在 $(x, y)$ 处的卷积运算。且有：\n$$ \\begin{equation*} G(x, y, \\sigma) = \\frac{1}{2\\pi \\sigma^2}e^{-(x^2+y^2)/2\\sigma^2} % \\label{eq:gaussian} \\end{equation*} $$\n为了有效地检测尺度空间中稳定关键点的位置，Lowe (Object recognition from local scale-invariant features, 1999) 提出利用高斯差分函数(difference-of-Gaussian) 与图像的卷积来求得尺度空间极值 $D(x, y, \\sigma)$。它可以通过间隔常数 $k$ 的相邻尺度的差分来计算：\n$$ \\begin{align*} D(x,y,\\sigma) \u0026= (G(x, y, k\\sigma) - G(x, y, \\sigma)) \\bigotimes I(x, y) \\cr \u0026= L(x, y, k\\sigma) - L(x, y, \\sigma) \\tag{1} \\end{align*} $$\n这样做的目的是为了减少计算量，因为高斯差分可以通过图像间简单的相减得到。此外，Lindeberg 的研究表明，高斯差分函数 $DoG$ 与尺度归一化的高斯拉普拉斯算子 (Laplacian of Gaussian)，$\\sigma^2\\nabla^2G$，是近似相等的。Lowe 在论文中向我们证明了如下结论：\n$$ \\begin{equation*} \\sigma\\nabla^2G = \\frac{\\partial G}{\\partial \\sigma} \\approx \\frac{G(x, y, k\\sigma) - G(x, y, \\sigma)}{k\\sigma - \\sigma} \\end{equation*} $$\n因此, 则有:\n$$ \\begin{equation*} G(x, y, k\\sigma) - G(x, y, \\sigma) \\approx (k - 1) \\sigma^2 \\nabla^2 G. \\end{equation*} $$\n式中因子 $(k-1)$ 在任何尺度上都是常数，因此不会影像极值位置。且 Lowe 发现近似误差对于极值探测和定位的稳定性几乎没有影响。\n 图 1 SIFT 中的图像金字塔。左侧尺度空间中的每一组图像，都是通过对初始图像重复进行高斯卷积产生得来的。相邻高斯图像相减得到了右侧的高斯差分图像。尺度空间中每一层图像都相对于上一层进行了 2 倍降采样。\n  高斯差分图像 $D(x, y, \\sigma)$ 金字塔的构造方法如图 1 所示。高斯金字塔共分 O 组 (Octave), 每组又分 S 层 (Layer)。组内各层图像的分辨率是相同的，即长和宽相同，但尺度逐渐增加，即越接近顶端图像越模糊。每一层的初始图像与高斯逐步卷积，产生由尺度空间中的常数因子 $k$ 分隔的图像，如左列所示。每一层的高斯图像金字塔完成之后，我们选取该层的第二张图像进行隔点降采样 (图像长和宽减小为原来的 $1/2$)，作为下一层的初始影像 (因此其尺度因子 $\\sigma$ 为上层图像的两倍)。SIFT 将每层尺度空间划分为整数 $s$ 个子层, 因此 $k=2^{1/s}$。所以为了覆盖全部的 $s$ 尺度, 高斯金字塔中每层至少要有 $s+3$ 张图像。高斯金字塔层中相邻图像之差构成了右侧的高斯差分图像金字塔。\n极值点的搜索是在高斯差分金字塔中进行的, 这些极值点就是候选的特征点。为了检测 $D(x, y, \\sigma)$ 中的局部最大值和最小值，SIFT 将每个采样点与当前图像中八个相邻像素的值以及上下层尺度中的九个相邻像素值进行对比 (如图 2)。这项搜索工作的计算成本非常低, 因为很多采样点在邻域像素值比较的过程中被排除了。\n 图 2 将采样点 (用 $\\times$ 表示) 像素值与当前及相邻两个尺度层的 3$\\times$3 邻域中的 26 个点 (用圆圈表示) 作比较，判断是否为极大值或极小值。\n  1.2 关键点的精确定位 由于极值点的搜索是在离散空间中进行的，并且这些离散空间还是经过不断采样得到的。通过局部极值探测确定候选点的位置和尺度之后, 我们需要通过三维二次函数拟合得到关键点的精确位置，以达到亚像素级的精度。\n根据 Invariant Features from Interest Point Groups (2002) ，尺度空间函数 $D(x, y, \\sigma)$ 泰勒展开到二次项的形式为：\n$$ \\begin{equation} D(\\mathbf{x})=D+\\frac{\\partial D}{\\partial \\mathbf{x}}^{T} \\mathbf{x}+\\frac{1}{2} \\mathbf{x}^{\\mathbf{T}} \\frac{\\partial^{2} D}{\\partial \\mathbf{x}^{2}} \\mathbf{x} % \\label{eq:dog-taylor} \\end{equation} \\tag{2} $$\n其中 $D$ 为 $D(x, y, \\sigma)$ 在关键点处的值，$\\mathbf{x}=(x, y, \\sigma)^T$ 是关键点的偏移量。令\n$$ \\frac{\\partial D(\\mathbf{x})}{\\partial\\mathbf{x}} = 0 $$\n即可得到 $\\mathbf{x}$ 的极值 $\\mathbf{\\hat{x}}$：\n$$ \\begin{equation} \\hat{\\mathbf{x}}=-\\frac{\\partial^{2} D^{-1}}{\\partial \\mathbf{x}^{2}} \\frac{\\partial D}{\\partial \\mathbf{x}} % \\label{eq:dog-3} \\end{equation} \\tag{3} $$\n如果 $\\hat{\\mathbf{x}}$ 在任意方向 $(x, y, \\sigma)$ 上大于 0.5，就意味着该关键点与另一采样非常接近，这时就用插值来代替关键点的位置。关键点假设偏移量 $\\hat{\\mathbf{x}})$ 即为关键点的确位置。为了保证结果的准确性，我们往往使用迭代的方法进行这一插值过程。\n定位到关键点的精确位置后，为提高匹配的稳定性，我们需要删除低对比度的点。将式 (3) 代入 (2) 得：\n$$ D(\\hat{\\mathbf{x}})=D+\\frac{1}{2} \\frac{\\partial D}{\\partial \\mathbf{x}} \\hat{\\mathbf{x}} $$\n式中 $D(\\hat{\\mathbf{x}})$ 可以用来衡量特征点的对比度，在 Lowe 的论文中，对比度 $|D(\\hat{\\mathbf{x}})|$ 小于 0.03 的极值点会被舍弃。\n而为了保证关键点的稳定性，仅仅舍弃低对比度的候选点是不够的。高斯差分函数在会产生很强的边缘效应，因此很容易受到噪声的干扰。所以我们也需要剔除掉这些不稳定的边缘点。\n高斯差分函数的相应峰值往往在横跨边缘的地方有较大的的主曲率，而在垂直边缘的地方有较小的主曲率。 主曲率可以通过 $2 \\times 2$ 的 Hessian 矩阵 $\\mathbf{H}$ 来计算：\n$$ \\begin{equation} \\mathbf{H}=\\left[ \\begin{array}{cc}{D_{x x}} \u0026 {D_{x y}} \\ {D_{x y}} \u0026 {D_{y y}}\\end{array}\\right] % \\label{eq:sift-hessian} \\end{equation} \\tag{4} $$\n其中，导数可以通过相邻样本点的差分来计算。\n$\\mathbf{H}$ 的特征值与 $D$ 的主曲率成正比。设 $\\alpha$ 是最大的特征值，$\\beta$ 是最小的特征值。特征值的总和与乘积可以分别通过 $\\mathbf{H}$ 的迹与行列式来计算：\n$$ \\begin{align*} \\text{Tr}(\\mathbf{H}) \u0026= D_{xx} + D_{yy} = \\alpha + \\beta \\ \\text{Det}(\\mathbf{H}) \u0026= D_{xx}D_{yy} - (D_{xy})^2 = \\alpha\\beta \\end{align*} $$\n如果行列式为负，则该候选点将被舍弃。令 $r$ 为最大特征值与最小特征值的比值，即 $r = \\alpha / \\beta$，则：\n$$ \\frac{\\operatorname{Tr}(\\mathbf{H})^{2}}{\\operatorname{Det}(\\mathbf{H})}=\\frac{(\\alpha+\\beta)^{2}}{\\alpha \\beta}=\\frac{(r \\beta+\\beta)^{2}}{r \\beta^{2}}=\\frac{(r+1)^{2}}{r} $$\n$\\frac{(r + 1)^2}{r}$ 的值在两个特征值相等时最小，并且随着 $r$ 的增大而增大。因此，为了检查主曲率的比值是否低于某个阈值 $r$，只需要判断：\n$$ \\frac{\\operatorname{Tr}(\\mathbf{H})^{2}}{\\operatorname{Det}(\\mathbf{H})}这样能够显著提高计算效率。同时我们取经验值 $r = 10$，即排除主曲率之比大于 10 的候选点。\n1.3 方向分配 经过上述两个步骤，我们可以完全找出一幅图像中的特征点，且它们对于尺度具有不变性。而根据局部图像属性为每个关键点指定某个方向，则关键点描述符可以通过该方向来表示，从而实现了旋转不变性。我们根据关键点的尺度选择与之最接近的高斯平滑图像 $L$，以使得所有计算满足了尺度不变性。对该尺度下的每一个图像采样点 $L(x, y)$，我们根据像素值差分来计算其梯度幅值 $m(x, y)$ 和方向 $\\theta(x, y)$：\n$$ \\begin{array}{c} {m(x, y) = \\sqrt{\\left[L(x+1, y)-L(x-1, y)\\right]^{2} + \\left[L(x, y+1)-L(x, y-1)\\right]^{2}}} \\cr\\cr {\\theta(x, y)=\\tan ^{-1}[L(x, y+1)-L(x, y-1)] /[L(x+1, y)-L(x-1, y)]} \\end{array} $$\nSIFT 根据关键点邻域内样本点的梯度方向来生成方向直方图。该直方图一共有 36 柱 (bin)，一柱 $10^{\\circ}$，覆盖整个 $0^{\\circ} \\sim 360^{\\circ}$ 的范围。添加到直方图中的每个样本点梯度方向都会根据其梯度幅值以及圆形高斯加权窗口 (其 $\\sigma$ 为关键点尺度的 1.5 倍) 进行加权。\n方向直方图的峰值对应于关键点局部梯度的主方向。同时，如果直方图中的某一柱的峰值高于其前后两柱，且大于大于主峰值的 80%，则我们在该位置处也创建具有该柱所代表的方向 (可视为辅方向) 的关键点。因此，如果一个方向直方图有很多幅值相近的峰值，那么在其相同尺度和位置处会有很多关键点，但它们的方向有所不同。根据 Lowe 的结论，大概只有 15% 的点被分配了多个方向，但这些方向能够显著提高匹配的稳定性。值得注意的是，每个直方图峰值对应方向是通过对其最接近的三个柱进行抛物线拟合、然后再插值得到的。\n1.4 关键点描述符 之前的步骤已经为每个关键点分配了图像位置、尺度和方向。在图像局部区域内，在图像局部区域内，这些参数可以重复地用以描述局部二维坐标系统，因为这些参数具有不变性。最后一步则是计算局部图像区域的描述符 (local descriptor)，该描述符具有高度的独特性，同时对于光照或 3D 视点的变化具有很高的鲁棒性。\n 图 3 首先通过计算关键点邻域中每个采样点的梯度大小和方向来创建关键点描述符，如左侧所示。计算过程由图像中的原型高斯加权窗口进行加权。然后在邻域范围内创建方向直方图。\n  图 3 展现了描述符的计算方法。首先，根据关键点的尺度选择相同模糊程度的高斯金字塔影像，对关键点邻域内像素进行采样以求得其图像梯度和方向。为了保证特征矢量具有旋转不变性，以关键点为中心，在其邻域内将描述符的坐标轴和梯度方向旋转至关键点的主方向。图 3 左侧图像中的每个小箭头代表该采样点的梯度方向和大小。使用高斯加权函数 ($\\sigma$ 等于描述符窗口宽度 1/2) 来为每个采样点的梯度幅值分配权重，图中圆圈代表窗口范围。\n然后在关键点 $4\\times 4$ 的邻域范围内创建方向直方图。关键点描述符如图 3 中右侧图像所示。每个直方图有八个方向，箭头长度对应与该直方图幅值的大小。该图中显示的是 $2 \\times 2$ 的方向直方图阵列，根据 Lowe 的论文结果，使用 $4 \\times 4$ 的方向直方图阵列，每个直方图有八个方向，可以提高匹配的稳健性。这样对于每个关键点就可以产生 $4 \\times 4 \\times 8 = 128$ 维的特征向量。\n此时的特征向量已经消去了尺度变化、旋转等几何变形因素的影响。最后还需对特征向量进行一定的修正，以进一步降低照明变化的影响。先将特征向量的归一化为单位长度。这样可以使得描述符不收光照仿射变换的影响。而对于非线性光照条件的变化，SIFT 通过对单位特征向量中的值进行阈值化处理，是每个值不大于 0.2 (该值通过实验验证得出)，然后再重新归一化为单位向量。最终得到的这个 128 维的向量即为 SIFT 特征向量。\n1.5 SIFT 匹配方法 SIFT 中的局部特征描述算子对于旋转、尺度缩放和亮度变化保持不变，且对于 3D 视角变化、仿射变换、 噪声等也具有很高的鲁棒性。得到两副目标影像的 SIFT 特征向量之后，我们采用关键点特征向量的欧氏距离作为两幅影像中关键点的相似性判定度量。在左图像中取出某个关键点，并通过遍历找出其与右影像中欧氏距离最接近的两个关键点。如果最邻近关键点与第二邻近关键点距离距离之比低于某个阈值 (经验值为 0.8)，则接受这一对匹配点。\n值得注意的是, 通过调整匹配过程中的阈值，我们可以影响到匹配结果的正确率与匹配点的数量。此外，SIFT 算子对很小的影像或少数几个物体也能产生大量的特征点，而 SIFT 匹配过程中采用了逐关键点遍历的方法, 这在对大尺寸影像处理时有着难以想象的计算开销。\n2. 算法实现-头文件 #pragma once #include #include  using namespace std; using namespace cv; /// 类定义 class SIFT { public: /// 构造函数  SIFT(int nOctaves = 4, int nOctaveLayers = 3, double sigma = 1.6, int nfeatures = 0, double contrastThreshold = 0.04, double edgeThreshold = 10); /// SIFT 类的重载操作符  void operator()(InputArray img, vectorKeyPoint\u0026 keyPoints, OutputArray descriptors); /// 建立高斯金字塔  void buildGaussianPyramid(const Mat\u0026 base, vectorMat\u0026 pyr); /// 建立高斯差分金字塔  void buildGaussianDifferencePyramid(vectorMat gauss_pyr, vectorMat\u0026 dog_pry); /// 尺度空间极值探测  void findScaleSpaceExtrema(vectorMat\u0026 gauss_pyr, vectorMat\u0026 dog_pyr, vectorKeyPoint\u0026 keyPoints); protected: int O;\t// 尺度空间数  int S;\t// 每层尺度空间的子层数  double sigma;\t// 尺度空间因子  int nfeatures;\t// 需要输出的特征点数量  double contrastThreshold;\t// 对比度阈值  double edgeThreshold;\t// 边缘阈值 }; /// 宏指令 // 初始图像的尺度，假设为 0.5 （by D.G.Lowe） static const double SIFT_INIT_SIGMA = 0.5; // 描述符数组中每个直方图的柱数 static const int SIFT_DESCR_HIST_BINS = 8; // 在关键点提取中忽略的边缘宽度 static const int SIFT_IMG_BORDER = 5; // 关键点插值的最大迭代次数 static const int SIFT_MAX_INTERP_STEPS = 5; // 方向分配中高斯函数的 σ static const double SIFT_ORI_SIG_FCTR = 1.5; // 方向分配中目标区域的半径 static const double SIFT_ORI_RADIUS = 3 * SIFT_ORI_SIG_FCTR; // 方向分配的梯度直方图柱数（范围为 0 ~ 360°，每 10° 一个柱，共 36 柱） static const int SIFT_ORI_HIST_BINS = 36; // 描述符直方图数组的默认宽度 static const int SIFT_DESCR_WIDTH = 4; // 确定单个描述符方向直方图的大小 static const double SIFT_DESCR_SCL_FCTR = 3.0; // 描述符向量元素大小的阈值 static const double SIFT_DESCR_MAG_THR = 0.2; // 用于将浮点数描述符转换为 uchar 类型 static const double SIFT_INT_DESCR_FCTR = 512; /// 函数声明 // 初始化基层图像矩阵 static Mat createInitialImage(const Mat\u0026 img, double _sigma); // 极值点的精确定位 static bool adjustLocalExtrema(const vectorMat\u0026 dog_pyr, KeyPoint\u0026 keyPoint, int octave, int\u0026 layer, int\u0026 r, int\u0026 c, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double _sigma); // 计算关键点局部影像的梯度方向直方图 static double calcOrientationHist(const Mat\u0026 img, Point pt, int radius, double _sigma, double* hist, int n); // 关键点特征描述 static void calcSIFTDescriptor(const Mat\u0026 img, Point2d kpt, double ori, double scl, int d, int n, double* dst); // 计算特征点描述符 static void calcDescriptors(const vectorMat\u0026 pyr, const vectorKeyPoint\u0026 keyPoints, Mat\u0026 descriptors, int nOctaveLayers); 未完待续…  参考：\n opencv/opencv_contrib/sift.cpp - github D. G. Lowe, Distinctive Image Features from Scale-Invariant Keypoints, International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004. opencv 2.4.9 源码分析 【OpenCV】SIFT原理与源码分析 - 小魏的修行路 - CSDN博客 SIFT算法详解 - zddhub的专栏 - CSDN博客 SIFT: Theory and Practice - AI Shack 张剑清，潘励，王树根，《摄影测量学(第二版)》   ",
  "wordCount" : "932",
  "inLanguage": "en",
  "datePublished": "2019-05-10T00:00:00Z",
  "dateModified": "2019-05-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Jifan"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://jifan.tech/posts/2019-05-10-opencv-4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Jifan's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://jifan.tech/imgs/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://jifan.tech" accesskey="h" title="Jifan&#39;s Blog (Alt + H)">Jifan&#39;s Blog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://jifan.tech/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://jifan.tech/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://jifan.tech/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://jifan.tech/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      OpenCV 源码分析：SIFT 算法原理与实现
    </h1>
    <div class="post-meta"><span title='2019-05-10 00:00:00 +0000 UTC'>May 10, 2019</span>&nbsp;·&nbsp;Jifan

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#1-sift-%e7%ae%97%e6%b3%95%e5%8e%9f%e7%90%86" aria-label="1. SIFT 算法原理">1. SIFT 算法原理</a><ul>
                        
                <li>
                    <a href="#11-%e5%b0%ba%e5%ba%a6%e7%a9%ba%e9%97%b4%e6%9e%81%e5%80%bc%e6%8e%a2%e6%b5%8b" aria-label="1.1 尺度空间极值探测">1.1 尺度空间极值探测</a></li>
                <li>
                    <a href="#12-%e5%85%b3%e9%94%ae%e7%82%b9%e7%9a%84%e7%b2%be%e7%a1%ae%e5%ae%9a%e4%bd%8d" aria-label="1.2 关键点的精确定位">1.2 关键点的精确定位</a></li>
                <li>
                    <a href="#13-%e6%96%b9%e5%90%91%e5%88%86%e9%85%8d" aria-label="1.3 方向分配">1.3 方向分配</a></li>
                <li>
                    <a href="#14-%e5%85%b3%e9%94%ae%e7%82%b9%e6%8f%8f%e8%bf%b0%e7%ac%a6" aria-label="1.4 关键点描述符">1.4 关键点描述符</a></li>
                <li>
                    <a href="#15-sift-%e5%8c%b9%e9%85%8d%e6%96%b9%e6%b3%95" aria-label="1.5 SIFT 匹配方法">1.5 SIFT 匹配方法</a></li></ul>
                </li>
                <li>
                    <a href="#2-%e7%ae%97%e6%b3%95%e5%ae%9e%e7%8e%b0-%e5%a4%b4%e6%96%87%e4%bb%b6" aria-label="2. 算法实现-头文件">2. 算法实现-头文件</a></li>
                <li>
                    <a href="#%e6%9c%aa%e5%ae%8c%e5%be%85%e7%bb%ad" aria-label="未完待续…">未完待续…</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><blockquote>
<p>本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 <a href="https://link.springer.com/article/10.1023%2FB%3AVISI.0000029664.99615.94">论文原文</a>、<a href="https://github.com/opencv/opencv_contrib/blob/master/modules/xfeatures2d/src/sift.cpp">GitHub上的源码</a> 以及 <a href="blog.csdn.net/zhaocj">@赵春江</a> 的 <a href="https://wenku.baidu.com/view/d7edd2464b73f242336c5ffa.html">opencv 2.4.9 源码分析</a>。</p>
</blockquote>
<h1 id="1-sift-算法原理">1. SIFT 算法原理<a hidden class="anchor" aria-hidden="true" href="#1-sift-算法原理">#</a></h1>
<p>Lowe 在 2004 年提出了尺度不变特征变换
(<em>Scale Invariant Feature Transform, SIFT</em>) 算法。
SIFT 主要由关键点探测器 (<em>detector</em>) 和描述符 (<em>descriptor</em>) 组成，它的实现分为以下四步:</p>
<ul>
<li><strong>尺度空间极值探测</strong> (<em>scale-space extrema detection</em>)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。</li>
<li><strong>关键点精确定位</strong> (<em>keypoint localization</em>)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。</li>
<li><strong>方向分配</strong> (<em>orientation assignment</em>)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。</li>
<li><strong>关键点描述符</strong> (<em>keypoint descriptor</em>)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。</li>
</ul>
<p>下面将对其进行详细阐释：</p>
<h2 id="11-尺度空间极值探测">1.1 尺度空间极值探测<a hidden class="anchor" aria-hidden="true" href="#11-尺度空间极值探测">#</a></h2>
<p>关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为<strong>尺度空间</strong> (<em>scale space</em>) 的尺度连续函数^[1]。</p>
<p>Koenderink (<a href="https://doi.org/10.1007/BF00336961">The structure of images, 1984</a>) 和 Lindeberg (<a href="https://doi.org/10.1007/BF01469346">Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993</a>) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \sigma)$，它是由可变尺度高斯函数 $G(x, y, \sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：</p>
<p>$$
\begin{equation*}
L(x, y, \sigma) = G(x, y, \sigma) \bigotimes I(x, y)
% \label{eq:scale-space}
\end{equation*}
$$</p>
<p>其中，$\bigotimes$ 表示在 $(x, y)$ 处的卷积运算。且有：</p>
<p>$$
\begin{equation*}
G(x, y, \sigma) = \frac{1}{2\pi \sigma^2}e^{-(x^2+y^2)/2\sigma^2}
% \label{eq:gaussian}
\end{equation*}
$$</p>
<p>为了有效地检测尺度空间中稳定关键点的位置，Lowe (<a href="https://dl.acm.org/citation.cfm?id=851523&amp;preflayout=flat">Object recognition from local scale-invariant features, 1999</a>) 提出利用高斯差分函数(<em>difference-of-Gaussian</em>) 与图像的卷积来求得尺度空间极值 $D(x, y, \sigma)$。它可以通过间隔常数 $k$ 的相邻尺度的差分来计算：</p>
<p>$$
\begin{align*}
D(x,y,\sigma) &amp;= (G(x, y, k\sigma) - G(x, y, \sigma)) \bigotimes I(x, y) \cr
&amp;= L(x, y, k\sigma) - L(x, y, \sigma)
\tag{1}
\end{align*}
$$</p>
<p>这样做的目的是为了减少计算量，因为高斯差分可以通过图像间简单的相减得到。此外，Lindeberg 的研究表明，高斯差分函数 $DoG$ 与尺度归一化的高斯拉普拉斯算子 (<em>Laplacian of Gaussian</em>)，$\sigma^2\nabla^2G$，是近似相等的。Lowe 在论文中向我们证明了如下结论：</p>
<p>$$
\begin{equation*}
\sigma\nabla^2G = \frac{\partial G}{\partial \sigma} \approx \frac{G(x, y, k\sigma) - G(x, y, \sigma)}{k\sigma - \sigma}
\end{equation*}
$$</p>
<p>因此, 则有:</p>
<p>$$
\begin{equation*}
G(x, y, k\sigma) - G(x, y, \sigma) \approx (k - 1) \sigma^2 \nabla^2 G.
\end{equation*}
$$</p>
<p>式中因子 $(k-1)$ 在任何尺度上都是常数，因此不会影像极值位置。且 Lowe 发现近似误差对于极值探测和定位的稳定性几乎没有影响。</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<figure class="align-center ">
    <img loading="lazy" src="https://i.loli.net/2019/06/24/5d10c3a2913d144249.jpg#center"
         alt="图 1 SIFT 中的图像金字塔。左侧尺度空间中的每一组图像，都是通过对初始图像重复进行高斯卷积产生得来的。相邻高斯图像相减得到了右侧的高斯差分图像。尺度空间中每一层图像都相对于上一层进行了 2 倍降采样。" width="50%"/> <figcaption>
            <p>图 1 SIFT 中的图像金字塔。左侧尺度空间中的每一组图像，都是通过对初始图像重复进行高斯卷积产生得来的。相邻高斯图像相减得到了右侧的高斯差分图像。尺度空间中每一层图像都相对于上一层进行了 2 倍降采样。</p>
        </figcaption>
</figure>

<p>高斯差分图像 $D(x, y, \sigma)$ 金字塔的构造方法如图 1 所示。高斯金字塔共分 O 组 (<em>Octave</em>), 每组又分 S 层 (<em>Layer</em>)。组内各层图像的分辨率是相同的，即长和宽相同，但尺度逐渐增加，即越接近顶端图像越模糊。每一层的初始图像与高斯逐步卷积，产生由尺度空间中的常数因子 $k$ 分隔的图像，如左列所示。每一层的高斯图像金字塔完成之后，我们选取该层的第二张图像进行隔点降采样 (图像长和宽减小为原来的 $1/2$)，作为下一层的初始影像 (因此其尺度因子 $\sigma$ 为上层图像的两倍)。SIFT 将每层尺度空间划分为整数 $s$ 个子层, 因此 $k=2^{1/s}$。所以为了覆盖全部的 $s$ 尺度, 高斯金字塔中每层至少要有 $s+3$ 张图像。高斯金字塔层中相邻图像之差构成了右侧的高斯差分图像金字塔。</p>
<p>极值点的搜索是在高斯差分金字塔中进行的, 这些极值点就是候选的特征点。为了检测 $D(x, y, \sigma)$ 中的局部最大值和最小值，SIFT 将每个采样点与当前图像中八个相邻像素的值以及上下层尺度中的九个相邻像素值进行对比 (如图 2)。这项搜索工作的计算成本非常低, 因为很多采样点在邻域像素值比较的过程中被排除了。</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<figure class="align-center ">
    <img loading="lazy" src="https://i.loli.net/2019/06/24/5d10ca14c06e278998.jpg#center"
         alt="图 2 将采样点 (用 $\times$ 表示) 像素值与当前及相邻两个尺度层的 3$\times$3 邻域中的 26 个点 (用圆圈表示) 作比较，判断是否为极大值或极小值。" width="50%"/> <figcaption>
            <p>图 2 将采样点 (用 $\times$ 表示) 像素值与当前及相邻两个尺度层的 3$\times$3 邻域中的 26 个点 (用圆圈表示) 作比较，判断是否为极大值或极小值。</p>
        </figcaption>
</figure>

<h2 id="12-关键点的精确定位">1.2 关键点的精确定位<a hidden class="anchor" aria-hidden="true" href="#12-关键点的精确定位">#</a></h2>
<p>由于极值点的搜索是在离散空间中进行的，并且这些离散空间还是经过不断采样得到的。通过局部极值探测确定候选点的位置和尺度之后, 我们需要通过三维二次函数拟合得到关键点的精确位置，以达到亚像素级的精度。</p>
<p>根据 <a href="https://www.researchgate.net/publication/221259493_Invariant_Features_from_Interest_Point_Groups">Invariant Features from Interest Point Groups (2002)</a> ，尺度空间函数 $D(x, y, \sigma)$ 泰勒展开到二次项的形式为：</p>
<p>$$
\begin{equation}
D(\mathbf{x})=D+\frac{\partial D}{\partial \mathbf{x}}^{T} \mathbf{x}+\frac{1}{2} \mathbf{x}^{\mathbf{T}} \frac{\partial^{2} D}{\partial \mathbf{x}^{2}} \mathbf{x}
% \label{eq:dog-taylor}
\end{equation}
\tag{2}
$$</p>
<p>其中 $D$ 为 $D(x, y, \sigma)$ 在关键点处的值，$\mathbf{x}=(x, y, \sigma)^T$ 是关键点的偏移量。令</p>
<p>$$
\frac{\partial D(\mathbf{x})}{\partial\mathbf{x}} = 0
$$</p>
<p>即可得到 $\mathbf{x}$ 的极值 $\mathbf{\hat{x}}$：</p>
<p>$$
\begin{equation}
\hat{\mathbf{x}}=-\frac{\partial^{2} D^{-1}}{\partial \mathbf{x}^{2}} \frac{\partial D}{\partial \mathbf{x}}
% \label{eq:dog-3}
\end{equation}
\tag{3}
$$</p>
<p>如果 $\hat{\mathbf{x}}$ 在任意方向 $(x, y, \sigma)$ 上大于 0.5，就意味着该关键点与另一采样非常接近，这时就用插值来代替关键点的位置。关键点假设偏移量 $\hat{\mathbf{x}})$ 即为关键点的确位置。为了保证结果的准确性，我们往往使用<strong>迭代</strong>的方法进行这一插值过程。</p>
<p>定位到关键点的精确位置后，为提高匹配的稳定性，我们需要删除低对比度的点。将式 (3) 代入 (2) 得：</p>
<p>$$
D(\hat{\mathbf{x}})=D+\frac{1}{2} \frac{\partial D}{\partial \mathbf{x}} \hat{\mathbf{x}}
$$</p>
<p>式中 $D(\hat{\mathbf{x}})$ 可以用来衡量特征点的对比度，在 Lowe 的论文中，对比度 $|D(\hat{\mathbf{x}})|$ 小于 0.03 的极值点会被舍弃。</p>
<p>而为了保证关键点的稳定性，仅仅舍弃低对比度的候选点是不够的。高斯差分函数在会产生很强的边缘效应，因此很容易受到噪声的干扰。所以我们也需要剔除掉这些不稳定的边缘点。</p>
<p>高斯差分函数的相应峰值往往在横跨边缘的地方有较大的的主曲率，而在垂直边缘的地方有较小的主曲率。
主曲率可以通过 $2 \times 2$ 的 Hessian 矩阵 $\mathbf{H}$ 来计算：</p>
<p>$$
\begin{equation}
\mathbf{H}=\left[ \begin{array}{cc}{D_{x x}} &amp; {D_{x y}} \ {D_{x y}} &amp; {D_{y y}}\end{array}\right]
% \label{eq:sift-hessian}
\end{equation}
\tag{4}
$$</p>
<p>其中，导数可以通过相邻样本点的差分来计算。</p>
<p>$\mathbf{H}$ 的特征值与 $D$ 的主曲率成正比。设 $\alpha$ 是最大的特征值，$\beta$ 是最小的特征值。特征值的总和与乘积可以分别通过 $\mathbf{H}$ 的迹与行列式来计算：</p>
<p>$$
\begin{align*}
\text{Tr}(\mathbf{H}) &amp;= D_{xx} + D_{yy} = \alpha + \beta \
\text{Det}(\mathbf{H}) &amp;= D_{xx}D_{yy} - (D_{xy})^2 = \alpha\beta
\end{align*}
$$</p>
<p>如果行列式为负，则该候选点将被舍弃。令 $r$ 为最大特征值与最小特征值的比值，即 $r = \alpha / \beta$，则：</p>
<p>$$
\frac{\operatorname{Tr}(\mathbf{H})^{2}}{\operatorname{Det}(\mathbf{H})}=\frac{(\alpha+\beta)^{2}}{\alpha \beta}=\frac{(r \beta+\beta)^{2}}{r \beta^{2}}=\frac{(r+1)^{2}}{r}
$$</p>
<p>$\frac{(r + 1)^2}{r}$ 的值在两个特征值相等时最小，并且随着 $r$ 的增大而增大。因此，为了检查主曲率的比值是否低于某个阈值 $r$，只需要判断：</p>
<p>$$
\frac{\operatorname{Tr}(\mathbf{H})^{2}}{\operatorname{Det}(\mathbf{H})}&lt;\frac{(r+1)^{2}}{r}
$$</p>
<p>这样能够显著提高计算效率。同时我们取经验值 $r = 10$，即排除主曲率之比大于 10 的候选点。</p>
<h2 id="13-方向分配">1.3 方向分配<a hidden class="anchor" aria-hidden="true" href="#13-方向分配">#</a></h2>
<p>经过上述两个步骤，我们可以完全找出一幅图像中的特征点，且它们对于尺度具有不变性。而根据局部图像属性为每个关键点指定某个方向，则关键点描述符可以通过该方向来表示，从而实现了旋转不变性。我们根据关键点的尺度选择与之最接近的高斯平滑图像 $L$，以使得所有计算满足了尺度不变性。对该尺度下的每一个图像采样点 $L(x, y)$，我们根据像素值差分来计算其梯度幅值 $m(x, y)$ 和方向 $\theta(x, y)$：</p>
<p>$$
\begin{array}{c}
{m(x, y) = \sqrt{\left[L(x+1, y)-L(x-1, y)\right]^{2} +
\left[L(x, y+1)-L(x, y-1)\right]^{2}}} \cr\cr
{\theta(x, y)=\tan ^{-1}[L(x, y+1)-L(x, y-1)] /[L(x+1, y)-L(x-1, y)]}
\end{array}
$$</p>
<p>SIFT 根据关键点邻域内样本点的梯度方向来生成方向直方图。该直方图一共有 36 柱 (bin)，一柱 $10^{\circ}$，覆盖整个 $0^{\circ} \sim 360^{\circ}$ 的范围。添加到直方图中的每个样本点梯度方向都会根据其梯度幅值以及圆形高斯加权窗口 (其 $\sigma$ 为关键点尺度的 1.5 倍) 进行加权。</p>
<p>方向直方图的峰值对应于关键点局部梯度的主方向。同时，如果直方图中的某一柱的峰值高于其前后两柱，且大于大于主峰值的 80%，则我们在该位置处也创建具有该柱所代表的方向 (可视为辅方向) 的关键点。因此，如果一个方向直方图有很多幅值相近的峰值，那么在其相同尺度和位置处会有很多关键点，但它们的方向有所不同。根据 Lowe 的结论，大概只有 15% 的点被分配了多个方向，但这些方向能够显著提高匹配的稳定性。值得注意的是，每个直方图峰值对应方向是通过对其最接近的三个柱进行抛物线拟合、然后再插值得到的。</p>
<h2 id="14-关键点描述符">1.4 关键点描述符<a hidden class="anchor" aria-hidden="true" href="#14-关键点描述符">#</a></h2>
<p>之前的步骤已经为每个关键点分配了图像位置、尺度和方向。在图像局部区域内，在图像局部区域内，这些参数可以重复地用以描述局部二维坐标系统，因为这些参数具有不变性。最后一步则是计算<strong>局部图像区域的描述符</strong> (<em>local descriptor</em>)，该描述符具有高度的独特性，同时对于光照或 3D 视点的变化具有很高的鲁棒性。</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<figure class="align-center ">
    <img loading="lazy" src="https://i.loli.net/2019/06/24/5d10d5ef9f70d81978.jpg#center"
         alt="图 3 首先通过计算关键点邻域中每个采样点的梯度大小和方向来创建关键点描述符，如左侧所示。计算过程由图像中的原型高斯加权窗口进行加权。然后在邻域范围内创建方向直方图。" width="70%"/> <figcaption>
            <p>图 3 首先通过计算关键点邻域中每个采样点的梯度大小和方向来创建关键点描述符，如左侧所示。计算过程由图像中的原型高斯加权窗口进行加权。然后在邻域范围内创建方向直方图。</p>
        </figcaption>
</figure>

<p>图 3 展现了描述符的计算方法。首先，根据关键点的尺度选择相同模糊程度的高斯金字塔影像，对关键点邻域内像素进行采样以求得其图像梯度和方向。为了保证特征矢量具有旋转不变性，以关键点为中心，在其邻域内将描述符的坐标轴和梯度方向旋转至关键点的主方向。图 3 左侧图像中的每个小箭头代表该采样点的梯度方向和大小。使用高斯加权函数 ($\sigma$ 等于描述符窗口宽度 1/2) 来为每个采样点的梯度幅值分配权重，图中圆圈代表窗口范围。</p>
<p>然后在关键点 $4\times 4$ 的邻域范围内创建方向直方图。关键点描述符如图 3 中右侧图像所示。每个直方图有八个方向，箭头长度对应与该直方图幅值的大小。该图中显示的是 $2 \times 2$ 的方向直方图阵列，根据 Lowe 的论文结果，使用 $4 \times 4$ 的方向直方图阵列，每个直方图有八个方向，可以提高匹配的稳健性。这样对于每个关键点就可以产生 $4 \times 4 \times 8 = 128$ 维的特征向量。</p>
<p>此时的特征向量已经消去了尺度变化、旋转等几何变形因素的影响。最后还需对特征向量进行一定的修正，以进一步降低照明变化的影响。先将特征向量的归一化为单位长度。这样可以使得描述符不收光照仿射变换的影响。而对于非线性光照条件的变化，SIFT 通过对单位特征向量中的值进行阈值化处理，是每个值不大于 0.2 (该值通过实验验证得出)，然后再重新归一化为单位向量。最终得到的这个 128 维的向量即为 SIFT 特征向量。</p>
<h2 id="15-sift-匹配方法">1.5 SIFT 匹配方法<a hidden class="anchor" aria-hidden="true" href="#15-sift-匹配方法">#</a></h2>
<p>SIFT 中的局部特征描述算子对于旋转、尺度缩放和亮度变化保持不变，且对于 3D 视角变化、仿射变换、
噪声等也具有很高的鲁棒性。得到两副目标影像的 SIFT 特征向量之后，我们采用关键点特征向量的欧氏距离作为两幅影像中关键点的相似性判定度量。在左图像中取出某个关键点，并通过遍历找出其与右影像中欧氏距离最接近的两个关键点。如果最邻近关键点与第二邻近关键点距离距离之比低于某个阈值 (经验值为 0.8)，则接受这一对匹配点。</p>
<p>值得注意的是, 通过调整匹配过程中的阈值，我们可以影响到匹配结果的正确率与匹配点的数量。此外，SIFT 算子对很小的影像或少数几个物体也能产生大量的特征点，而 SIFT 匹配过程中采用了逐关键点遍历的方法, 这在对大尺寸影像处理时有着难以想象的计算开销。</p>
<h1 id="2-算法实现-头文件">2. 算法实现-头文件<a hidden class="anchor" aria-hidden="true" href="#2-算法实现-头文件">#</a></h1>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="cp">#pragma once
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;opencv2/opencv.hpp&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">using</span> <span class="k">namespace</span> <span class="n">cv</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">/// 类定义
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">SIFT</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1">/// 构造函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">SIFT</span><span class="p">(</span><span class="kt">int</span> <span class="n">nOctaves</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nOctaveLayers</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="kt">double</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.6</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nfeatures</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="kt">double</span> <span class="n">contrastThreshold</span> <span class="o">=</span> <span class="mf">0.04</span><span class="p">,</span> <span class="kt">double</span> <span class="n">edgeThreshold</span> <span class="o">=</span> <span class="mi">10</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">/// SIFT 类的重载操作符
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">operator</span><span class="p">()(</span><span class="n">InputArray</span> <span class="n">img</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">KeyPoint</span><span class="o">&gt;&amp;</span> <span class="n">keyPoints</span><span class="p">,</span> <span class="n">OutputArray</span> <span class="n">descriptors</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">/// 建立高斯金字塔
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">buildGaussianPyramid</span><span class="p">(</span><span class="k">const</span> <span class="n">Mat</span><span class="o">&amp;</span> <span class="n">base</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">pyr</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">/// 建立高斯差分金字塔
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">buildGaussianDifferencePyramid</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;</span> <span class="n">gauss_pyr</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">dog_pry</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">/// 尺度空间极值探测
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">findScaleSpaceExtrema</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">gauss_pyr</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">dog_pyr</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">KeyPoint</span><span class="o">&gt;&amp;</span> <span class="n">keyPoints</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">protected</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">O</span><span class="p">;</span>			<span class="c1">// 尺度空间数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">S</span><span class="p">;</span>			<span class="c1">// 每层尺度空间的子层数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">double</span> <span class="n">sigma</span><span class="p">;</span>		<span class="c1">// 尺度空间因子
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">nfeatures</span><span class="p">;</span>		<span class="c1">// 需要输出的特征点数量
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">double</span> <span class="n">contrastThreshold</span><span class="p">;</span>	<span class="c1">// 对比度阈值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">double</span> <span class="n">edgeThreshold</span><span class="p">;</span>	<span class="c1">// 边缘阈值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">/// 宏指令
</span></span></span><span class="line"><span class="cl"><span class="c1">// 初始图像的尺度，假设为 0.5 （by D.G.Lowe）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_INIT_SIGMA</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 描述符数组中每个直方图的柱数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">SIFT_DESCR_HIST_BINS</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 在关键点提取中忽略的边缘宽度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">SIFT_IMG_BORDER</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 关键点插值的最大迭代次数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">SIFT_MAX_INTERP_STEPS</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 方向分配中高斯函数的 σ
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_ORI_SIG_FCTR</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 方向分配中目标区域的半径
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_ORI_RADIUS</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">SIFT_ORI_SIG_FCTR</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 方向分配的梯度直方图柱数（范围为 0 ~ 360°，每 10° 一个柱，共 36 柱）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">SIFT_ORI_HIST_BINS</span> <span class="o">=</span> <span class="mi">36</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 描述符直方图数组的默认宽度
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">SIFT_DESCR_WIDTH</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 确定单个描述符方向直方图的大小
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_DESCR_SCL_FCTR</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 描述符向量元素大小的阈值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_DESCR_MAG_THR</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 用于将浮点数描述符转换为 uchar 类型
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">SIFT_INT_DESCR_FCTR</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">/// 函数声明
</span></span></span><span class="line"><span class="cl"><span class="c1">// 初始化基层图像矩阵
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="n">Mat</span> <span class="nf">createInitialImage</span><span class="p">(</span><span class="k">const</span> <span class="n">Mat</span><span class="o">&amp;</span> <span class="n">img</span><span class="p">,</span> <span class="kt">double</span> <span class="n">_sigma</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 极值点的精确定位
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="kt">bool</span> <span class="nf">adjustLocalExtrema</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">dog_pyr</span><span class="p">,</span> <span class="n">KeyPoint</span><span class="o">&amp;</span> <span class="n">keyPoint</span><span class="p">,</span> <span class="kt">int</span> <span class="n">octave</span><span class="p">,</span> <span class="kt">int</span><span class="o">&amp;</span> <span class="n">layer</span><span class="p">,</span> <span class="kt">int</span><span class="o">&amp;</span> <span class="n">r</span><span class="p">,</span> <span class="kt">int</span><span class="o">&amp;</span> <span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nOctaveLayers</span><span class="p">,</span> <span class="kt">double</span> <span class="n">contrastThreshold</span><span class="p">,</span> <span class="kt">double</span> <span class="n">edgeThreshold</span><span class="p">,</span> <span class="kt">double</span> <span class="n">_sigma</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 计算关键点局部影像的梯度方向直方图
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="kt">double</span> <span class="nf">calcOrientationHist</span><span class="p">(</span><span class="k">const</span> <span class="n">Mat</span><span class="o">&amp;</span> <span class="n">img</span><span class="p">,</span> <span class="n">Point</span> <span class="n">pt</span><span class="p">,</span> <span class="kt">int</span> <span class="n">radius</span><span class="p">,</span> <span class="kt">double</span> <span class="n">_sigma</span><span class="p">,</span> <span class="kt">double</span><span class="o">*</span> <span class="n">hist</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 关键点特征描述
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="kt">void</span> <span class="nf">calcSIFTDescriptor</span><span class="p">(</span><span class="k">const</span> <span class="n">Mat</span><span class="o">&amp;</span> <span class="n">img</span><span class="p">,</span> <span class="n">Point2d</span> <span class="n">kpt</span><span class="p">,</span> <span class="kt">double</span> <span class="n">ori</span><span class="p">,</span> <span class="kt">double</span> <span class="n">scl</span><span class="p">,</span> <span class="kt">int</span> <span class="n">d</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="kt">double</span><span class="o">*</span> <span class="n">dst</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 计算特征点描述符
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">static</span> <span class="kt">void</span> <span class="nf">calcDescriptors</span><span class="p">(</span><span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Mat</span><span class="o">&gt;&amp;</span> <span class="n">pyr</span><span class="p">,</span> <span class="k">const</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">KeyPoint</span><span class="o">&gt;&amp;</span> <span class="n">keyPoints</span><span class="p">,</span> <span class="n">Mat</span><span class="o">&amp;</span> <span class="n">descriptors</span><span class="p">,</span> <span class="kt">int</span> <span class="n">nOctaveLayers</span><span class="p">);</span>
</span></span></code></pre></div><h1 id="未完待续">未完待续…<a hidden class="anchor" aria-hidden="true" href="#未完待续">#</a></h1>
<blockquote>
<p><strong>参考：</strong></p>
<ol>
<li><a href="https://github.com/opencv/opencv_contrib/blob/master/modules/xfeatures2d/src/sift.cpp">opencv/opencv_contrib/sift.cpp - github</a></li>
<li>D. G. Lowe, <em><a href="https://doi.org/10.1023/B:VISI.0000029664.99615.94">Distinctive Image Features from Scale-Invariant Keypoints</a></em>, International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004.</li>
<li><a href="https://wenku.baidu.com/view/d7edd2464b73f242336c5ffa.html">opencv 2.4.9 源码分析</a></li>
<li><a href="https://blog.csdn.net/xiaowei_cqu/article/details/8069548">【OpenCV】SIFT原理与源码分析 - 小魏的修行路 - CSDN博客</a></li>
<li><a href="https://blog.csdn.net/zddblog/article/details/7521424">SIFT算法详解 - zddhub的专栏 - CSDN博客</a></li>
<li><a href="http://aishack.in/tutorials/sift-scale-invariant-feature-transform-introduction/">SIFT: Theory and Practice - AI Shack</a></li>
<li>张剑清，潘励，王树根，《摄影测量学(第二版)》</li>
</ol>
</blockquote>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://jifan.tech/tags/opencv/">OpenCV</a></li>
      <li><a href="https://jifan.tech/tags/c&#43;&#43;/">C&#43;&#43;</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://jifan.tech/posts/2019-04-18-opencv-3/">
    <span class="title">Next Page »</span>
    <br>
    <span>OpenCV 相机检校：原理及简单实现</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://jifan.tech">Jifan&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css" integrity="sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js" integrity="sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: '\\(', right: '\\)', display: false},
                {left: '\\[', right: '\\]', display: true}
            ],
            
            throwOnError : false
        });
    });
</script>


<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>