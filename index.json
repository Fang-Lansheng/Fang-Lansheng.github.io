[{"content":"1. MySQL Error in log file Server stopped immediately after running ./server in shell, and output an error MySQL Error in log file.\n  Find the source of the error: Although the error log is fairly vague, it\u0026rsquo;s not difficult to find out that it was thrown by the function connection_pool::init in the file CGImysql/sql_connection_pool.cpp.\n mysql_init(): return an initialized MYSQL* handler (i.e. a MYSQL object suitable for mysql_real_connect()), or NULL in case of insufficient memory. mysql_real_connect(): return a MYSQL* connection handler if the connection was successful, NULL if the connection was unsuccessful. It\u0026rsquo;s no doubt that detailed error output helps us to locate the problem.  // Note: due to the refactoring of the project, this code no longer corresponds to // the existing one, but the idea of solving this problem remains similar. void connection_pool::init(string url, string User, string PassWord, string DBName, int Port, int MaxConn, int close_log) { m_url = url; m_Port = Port; m_User = User; m_PassWord = PassWord; m_DatabaseName = DBName; m_close_log = close_log; for (int i = 0; i \u0026lt; MaxConn; i++) { MYSQL* con = NULL; con = mysql_init(con); if (con == NULL) { // If `mysql_init()` return NULL, print corresponding error log.  // LOG_ERROR(\u0026#34;MySQL Error\u0026#34;);  LOG_ERROR(\u0026#34;MySQL Error: `mysql_init()` return NULL, maybe there was insufficient memory to allocate a new object.\u0026#34;); exit(1); } MYSQL* temp = con; con = mysql_real_connect(con, url.c_str(), User.c_str(), PassWord.c_str(), DBName.c_str(), Port, NULL, 0); if (con == NULL) { // If `mysql_real_connect()` return NULL, print correspnding error log.  // LOG_ERROR(\u0026#34;MySQL Error\u0026#34;);  string err_info( mysql_error(temp) ); err_info = (string(\u0026#34;MySQL Error [errno=\u0026#34;) + std::to_string(mysql_errno(temp)) + string(\u0026#34;]: \u0026#34;) + err_info); LOG_ERROR( err_info.c_str() ); exit(1); } connList.push_back(con); ++m_FreeConn; } reserve = sem(m_FreeConn); m_MaxConn = m_FreeConn; }   Identify error type: after modifying the log output style, the following error ocurrs:\n2022-04-03 19:30:29.360109 [erro]: MySQL Error [errno=1045]: Access denied for user \u0026#39;USER_NAME\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES)   Solutions:\n Check whether the database information in the main.cpp file is correct, including USER_NAME, PASSWORD, and DATABASE_NAME. Verify that user USER_NAME has access privileges to the target database DATABASE_NAME.    ","permalink":"https://jifan.tech/projects/tiny-web-server/problems/","summary":"1. MySQL Error in log file Server stopped immediately after running ./server in shell, and output an error MySQL Error in log file.\n  Find the source of the error: Although the error log is fairly vague, it\u0026rsquo;s not difficult to find out that it was thrown by the function connection_pool::init in the file CGImysql/sql_connection_pool.cpp.\n mysql_init(): return an initialized MYSQL* handler (i.e. a MYSQL object suitable for mysql_real_connect()), or NULL in case of insufficient memory.","title":"Tiny Web Server: Problems Encountered"},{"content":" TL,DR.\n The select() and poll() are system calls to monitor file descriptors. And the epoll is a Linux-specified API to implement I/O multiplexing with higher performance when it comes to large numbers of file descriptors.   1. Why not blocking I/O? Under the convensional file I/O model, a process performs I/O on just one file descriptor, named fd, at a time, and each I/O system call blocks until the data is transferred. For example, when reading from the pipe,\n a read() call normally blocks if no data is currently persent in the pipe. And, a write() call blocks if there is insufficient space in the pipe to hold the data to be written.  It\u0026rsquo;s no doubt that the traditional blocking I/O model is already stretched when we need to monitor multiple file descriptors, or avoid blocking the current process if I/O is not possible on a file descriptor.\nThere are two direct approaches to partially address these needs:\n Nonblocking I/O. Use of multiple processes or threads.  Nonblocking I/O allows us to periodically check (\u0026ldquo;poll\u0026rdquo;) whether I/O is possible. For expample, we can make an input file descriptor nonblocking, and then periodically performing nonblocking reads. If we need to monitor multiple file descriptor, then we mark them all nonblocking, and poll each of them in turn. However, polling in this manner is usually undesirable. If polling is done only infrequently, then the latency before an application responds to an I/O event may be unacceptably long; on the other hand, polling in a tight loop wastes CPU time.\nIf we need to handle I/O on multiple file descriptors, we can create one child process or thread for each descriptor. To do so, however, an inter-process/thread communication mechanism is needed to inform the parent about the status of the I/O operations, which demanding more resources and can lead to programming difficulties.\nFortunately, modern Linux provides the following alternative I/O models.\nI/O multiplexing: select() \u0026amp; poll() I/O multiplexing allows a process to simultaneously monitor multiple file descriptors to find out whether I/O is possible on any of them. The select() and poll() system calls perform I/O multiplexing.\nSignal-driven I/O Signal-driven I/O is a technique whereby a process requests that the kernel send it a signal when input is avaiable or data can be written on a specified file descriptor. The process can then carry on performing other activities, and is notified when I/O becomes possible via receipt of the signal. When monitoring large numbers of file descriptors, signal-driven I/O provides significantly better performance than select() and poll().\nThe Linux-specific epoll API The epoll API is a Linux-specifc feature that first appeared in Linux 2.6 (?). Like the I/O multiplexing APIs, the epoll API allows a process to monitor multiple file descriptors to see if I/O is possible on any of them. Like signal-driven I/O, the epoll API provides much better performance when monitoring large numbers of file descriptors.\n","permalink":"https://jifan.tech/posts/2022-03-28-io-models/","summary":"TL,DR.\n The select() and poll() are system calls to monitor file descriptors. And the epoll is a Linux-specified API to implement I/O multiplexing with higher performance when it comes to large numbers of file descriptors.   1. Why not blocking I/O? Under the convensional file I/O model, a process performs I/O on just one file descriptor, named fd, at a time, and each I/O system call blocks until the data is transferred.","title":"I/O multiplexing: select, poll and epoll"},{"content":" Before starting the TinyWebServer project, I took a quick look at what a web server is. This article is a general summary of it, based on my current basic understanding.\n 1. What is a web server? The term web server can refer to software or underlying hardware.\n On the hardware side, a web server is a computer that:  stores web server software and a website\u0026rsquo;s component files (e.g., HTML documents, images, CSS stylesheets and JavaScript files). connects to the Internet and supports physical data interchange with other devices connected to the web.   On the software side, a web server includes several parts that control how web users access hosted files.  At a minimum, this is an HTTP server. An HTTP server is a software that understands URLs (web address) and HTTP (the network protocal created to dsitribute web content). An HTTP server can be accessed through the domain names of the websites it stores. Besides HTTP, web servers can also support SMTP and FTP, used for email, file transfer and storage. It can deliver the content of hosted websites to the end usrer\u0026rsquo;s device, and also can accept and stores resources sent from the user agent if configured to do so.     Figure 1. A basic Client-Server model. (Image source: developer.mozilla.org)\n  Typically, web servers are classified as static and dynamic.\n A static web server, or stack, consists of a computer (hardware) with an HTTP server (software). We call it \u0026ldquo;static\u0026rdquo; because the server sends its hosted files as-is to your browser. A dynamic web server consists of a static web server plus extra software, most commonly an application server and a database. We call it \u0026ldquo;dynamic\u0026rdquo; because the application server updates the hosted files before sending content to your browser via the HTTP server.  Currently, the most used Web Servers in the world are Apache HTTP Server, Nginx, Microsoft-IIS, OpenResty, etc.\n2. How a client and server communicate? Normally, a client makes HTTP requests to a server.\n The server responds to the client\u0026rsquo;s HTTP requests. And the server and also populate data into a client cache, in advance of it being requested, through a mechanism called a server push. When requesting a file via HTTP, the client must provice the file\u0026rsquo;s URL. The web server must answer every HTTP request, at least with an error message.  On a web server, the HTTP server is responsible for processing and answering incoming requests.\n Upon receiving a request, an HTTP server first checks if the requested URL matches an existing file. If so, the web server sends the file content back to the browser. If not, an appicatoin server builds the necesary file. If neither process is possible, the web server returns an error message to the browser, most commonly 404 Not Found (indicates that the server cannot find the requested resource).  3. Performances To improve the user experience (on client / browser side), a web server should reply quickly (as soon as possible) to client requests; unless content response is throttled (by configuration) for some type of files (e.g. big or huge files), also returned data content should be sent as fast as possible (high transfer speed).\n3.1 Performance metrics For web server software, main key performance metrics usually are at least the following ones:\n number of requests per second (RPS); It\u0026rsquo;s similar to QPS (queries per second), depending on HTTP version and configuration, type of HTTP requests and other operating conditions; number of connections per second (CPS), is the number of connections per second accepted by web server; network latency + response time for each new client request; throughput of responses, in bytes per second.  3.2 Benchmarking Web server benchmarking is the process of estimating a web server performance in order to find if the server can serve sufficiently high workload. The measurements must be performed under a varying load of clients and requests per client.\nLoad testing (stress/performance testing) a web server can be performed using automation/analysis tools.\n Refrences:\n What is a web server? - Learn web development | MDN Web server - Wikipedia   ","permalink":"https://jifan.tech/posts/2022-03-02-web-server/","summary":"Before starting the TinyWebServer project, I took a quick look at what a web server is. This article is a general summary of it, based on my current basic understanding.\n 1. What is a web server? The term web server can refer to software or underlying hardware.\n On the hardware side, a web server is a computer that:  stores web server software and a website\u0026rsquo;s component files (e.","title":"A Primer on Web Server"},{"content":" GitHub repository: https://github.com/Fang-Lansheng/EasyCounting.\n Features  Preprocessing code and dataloader of multiple crowd/vehicle datasets. PyTorch implementations of multiple SOTA methods. Standardized model training/testing process. Config system with modular and inheritance design.  Requirements More details in reqirement.txt.\nQuickstart  Append the project\u0026rsquo;s path to PYTHONPATH and make sure to use absolute imports.  export PYTHONPATH=\u0026#34;${PYTHONPATH}:/path/to/your/project\u0026#34; Preprocess the dataset.  # Take ShanghaiTech Part_A for example. python datasets/SHHA/generate_dataset.py --data-root ~/workspace/datasets/ShanghaiTech/part_A_final  Arguments of generate_dataset.py  --data-root:  Path to the raw dataset downloaded from the Internet. Default: ~/workspace/datasets/{DATASET_NAME}.   --destination:  Where the preprocessed data will be saved in. Default: {PROJECT_PATH}/processed_data/{DATASET_NAME}.   --resize-shape:  Usage: --resize-shape {width} {height}. Default: None (no resizing).    \nEdit the configuration (if needed) and then enjoy training your network!  # Like, train CSRNet on ShanghaiTech Part_A dataset. python train.py --config configs/CSRNet/SHHA.py Supported methods and datasets Methods    Method Year Venue Experiments Source Code     CSRNet 2018 CVPR Link leeyeehoo/CSRNet-pytorch   DM_Count 2020 NIPS Link cvlab-stonybrook/DM-Count   PSNet 2020 arXiv Link daimuuc/PyramidScaleNetwork   STDNet 2021 TMM Link stk513486/STDNet    Datasets  Crowd counting datasets     Dataset Year Attributes Avg. Resolution No.Samples No.Instance Avg.Count Source     Fudan-ShanghaiTech 2019 Video 1080×1920 15,000 394,081 27 Homepage   Venice 2019 Video 720×1280 167 - - Homepage   UCF-QNRF 2018 Congested 2013×2902 1,535 1,251,642 501 Homepage   ShanghaiTech Part_A 2016 Congested 589×868 482 241,677 501 Homepage Kaggle   ShanghaiTech Part_B 2016 Free Scenes 768×1024 716 88,488 123 Homepage Kaggle   MALL 2012 Video 480×640 2,000 62,325 31 Homepage   UCSD 2008 Video 158×238 2,000 49,885 25 Homepage    Vehicle counting datasets     Dataset Year Attributes Avg. Resolution No.Samples No.Instance Avg.Count Source     UAVCC 2020 Drone-view 540×1024 885 - - -   CARPK 2017 Drone-view 720×1080 1,448 - - Homepage   TRANCOS 2015 Surveillance-view 2013×2902 1,244 46,796 37 Homepage    Acknowledgement   This project was inspired by:\n gjy3035/C-3-Framework: An open-source PyTorch code for crowd counting open-mmlab/mmsegmentation: OpenMMLab Semantic Segmentation Toolbox and Benchmark    Some codes were borrowed from:\n gjy3035/C-3-Framework open-mmlab/mmsegmentation leeyeehoo/CSRNet-pytorch cvlab-stonybrook/DM-Count daimuuc/PyramidScaleNetwork stk513486/STDNet    Cover image source: UCF-QNRF dataset.\n  Many thanks!\n","permalink":"https://jifan.tech/projects/easy-counting/","summary":"An open source crowd/vehicle counting toolbox based on PyTorch.","title":"EasyCounting"},{"content":" 本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的 opencv 2.4.9 源码分析。\n 1. SIFT 算法原理 Lowe 在 2004 年提出了尺度不变特征变换 (Scale Invariant Feature Transform, SIFT) 算法。 SIFT 主要由关键点探测器 (detector) 和描述符 (descriptor) 组成，它的实现分为以下四步:\n 尺度空间极值探测 (scale-space extrema detection)：通过高斯差分函数搜索所有尺度和图像位置，以识别对于尺度和方向不变的潜在兴趣点。 关键点精确定位 (keypoint localization)：精确确定每个候选点的尺度与亚像素级位置，根据其稳定性阈值选择关键点。 方向分配 (orientation assignment)：基于图像的局部梯度方向，为每个特性点分配一个或多个方向角度。所有后续的操作都是相对于所确定下来的特征点的角度、尺度和位置的基础上进行的，因此特征点具有角度、尺度和位置的不变性。 关键点描述符 (keypoint descriptor)：在所选定的尺度空间内，测量特征点邻域区域的局部图像梯度，将这些梯度转换成一种允许局部较大程度的形状变形和亮度变化的描述符形式。  下面将对其进行详细阐释：\n1.1 尺度空间极值探测 关键点检测的第一阶段是识别可以在同一对象的不同视图下重复分配的位置和尺度。通过在素有可能的尺度进行搜索，可以检测出对图像尺度不变的稳定特征。这一过程中使用到的是被称为尺度空间 (scale space) 的尺度连续函数^[1]。\nKoenderink (The structure of images, 1984) 和 Lindeberg (Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention, 1993) 已经证明，唯一可能的尺度空间核是高斯函数。因此，图像的尺度空间被定义为函数 $L(x, y, \\sigma)$，它是由可变尺度高斯函数 $G(x, y, \\sigma)$ 与输入图像 $I(x,y)$ 卷积得到的：\n$$ \\begin{equation*} L(x, y, \\sigma) = G(x, y, \\sigma) \\bigotimes I(x, y) % \\label{eq:scale-space} \\end{equation*} $$\n其中，$\\bigotimes$ 表示在 $(x, y)$ 处的卷积运算。且有：\n$$ \\begin{equation*} G(x, y, \\sigma) = \\frac{1}{2\\pi \\sigma^2}e^{-(x^2+y^2)/2\\sigma^2} % \\label{eq:gaussian} \\end{equation*} $$\n为了有效地检测尺度空间中稳定关键点的位置，Lowe (Object recognition from local scale-invariant features, 1999) 提出利用高斯差分函数(difference-of-Gaussian) 与图像的卷积来求得尺度空间极值 $D(x, y, \\sigma)$。它可以通过间隔常数 $k$ 的相邻尺度的差分来计算：\n$$ \\begin{align*} D(x,y,\\sigma) \u0026amp;= (G(x, y, k\\sigma) - G(x, y, \\sigma)) \\bigotimes I(x, y) \\cr \u0026amp;= L(x, y, k\\sigma) - L(x, y, \\sigma) \\tag{1} \\end{align*} $$\n这样做的目的是为了减少计算量，因为高斯差分可以通过图像间简单的相减得到。此外，Lindeberg 的研究表明，高斯差分函数 $DoG$ 与尺度归一化的高斯拉普拉斯算子 (Laplacian of Gaussian)，$\\sigma^2\\nabla^2G$，是近似相等的。Lowe 在论文中向我们证明了如下结论：\n$$ \\begin{equation*} \\sigma\\nabla^2G = \\frac{\\partial G}{\\partial \\sigma} \\approx \\frac{G(x, y, k\\sigma) - G(x, y, \\sigma)}{k\\sigma - \\sigma} \\end{equation*} $$\n因此, 则有:\n$$ \\begin{equation*} G(x, y, k\\sigma) - G(x, y, \\sigma) \\approx (k - 1) \\sigma^2 \\nabla^2 G. \\end{equation*} $$\n式中因子 $(k-1)$ 在任何尺度上都是常数，因此不会影像极值位置。且 Lowe 发现近似误差对于极值探测和定位的稳定性几乎没有影响。\n 图 1 SIFT 中的图像金字塔。左侧尺度空间中的每一组图像，都是通过对初始图像重复进行高斯卷积产生得来的。相邻高斯图像相减得到了右侧的高斯差分图像。尺度空间中每一层图像都相对于上一层进行了 2 倍降采样。\n  高斯差分图像 $D(x, y, \\sigma)$ 金字塔的构造方法如图 1 所示。高斯金字塔共分 O 组 (Octave), 每组又分 S 层 (Layer)。组内各层图像的分辨率是相同的，即长和宽相同，但尺度逐渐增加，即越接近顶端图像越模糊。每一层的初始图像与高斯逐步卷积，产生由尺度空间中的常数因子 $k$ 分隔的图像，如左列所示。每一层的高斯图像金字塔完成之后，我们选取该层的第二张图像进行隔点降采样 (图像长和宽减小为原来的 $1/2$)，作为下一层的初始影像 (因此其尺度因子 $\\sigma$ 为上层图像的两倍)。SIFT 将每层尺度空间划分为整数 $s$ 个子层, 因此 $k=2^{1/s}$。所以为了覆盖全部的 $s$ 尺度, 高斯金字塔中每层至少要有 $s+3$ 张图像。高斯金字塔层中相邻图像之差构成了右侧的高斯差分图像金字塔。\n极值点的搜索是在高斯差分金字塔中进行的, 这些极值点就是候选的特征点。为了检测 $D(x, y, \\sigma)$ 中的局部最大值和最小值，SIFT 将每个采样点与当前图像中八个相邻像素的值以及上下层尺度中的九个相邻像素值进行对比 (如图 2)。这项搜索工作的计算成本非常低, 因为很多采样点在邻域像素值比较的过程中被排除了。\n 图 2 将采样点 (用 $\\times$ 表示) 像素值与当前及相邻两个尺度层的 3$\\times$3 邻域中的 26 个点 (用圆圈表示) 作比较，判断是否为极大值或极小值。\n  1.2 关键点的精确定位 由于极值点的搜索是在离散空间中进行的，并且这些离散空间还是经过不断采样得到的。通过局部极值探测确定候选点的位置和尺度之后, 我们需要通过三维二次函数拟合得到关键点的精确位置，以达到亚像素级的精度。\n根据 Invariant Features from Interest Point Groups (2002) ，尺度空间函数 $D(x, y, \\sigma)$ 泰勒展开到二次项的形式为：\n$$ \\begin{equation} D(\\mathbf{x})=D+\\frac{\\partial D}{\\partial \\mathbf{x}}^{T} \\mathbf{x}+\\frac{1}{2} \\mathbf{x}^{\\mathbf{T}} \\frac{\\partial^{2} D}{\\partial \\mathbf{x}^{2}} \\mathbf{x} % \\label{eq:dog-taylor} \\end{equation} \\tag{2} $$\n其中 $D$ 为 $D(x, y, \\sigma)$ 在关键点处的值，$\\mathbf{x}=(x, y, \\sigma)^T$ 是关键点的偏移量。令\n$$ \\frac{\\partial D(\\mathbf{x})}{\\partial\\mathbf{x}} = 0 $$\n即可得到 $\\mathbf{x}$ 的极值 $\\mathbf{\\hat{x}}$：\n$$ \\begin{equation} \\hat{\\mathbf{x}}=-\\frac{\\partial^{2} D^{-1}}{\\partial \\mathbf{x}^{2}} \\frac{\\partial D}{\\partial \\mathbf{x}} % \\label{eq:dog-3} \\end{equation} \\tag{3} $$\n如果 $\\hat{\\mathbf{x}}$ 在任意方向 $(x, y, \\sigma)$ 上大于 0.5，就意味着该关键点与另一采样非常接近，这时就用插值来代替关键点的位置。关键点假设偏移量 $\\hat{\\mathbf{x}})$ 即为关键点的确位置。为了保证结果的准确性，我们往往使用迭代的方法进行这一插值过程。\n定位到关键点的精确位置后，为提高匹配的稳定性，我们需要删除低对比度的点。将式 (3) 代入 (2) 得：\n$$ D(\\hat{\\mathbf{x}})=D+\\frac{1}{2} \\frac{\\partial D}{\\partial \\mathbf{x}} \\hat{\\mathbf{x}} $$\n式中 $D(\\hat{\\mathbf{x}})$ 可以用来衡量特征点的对比度，在 Lowe 的论文中，对比度 $|D(\\hat{\\mathbf{x}})|$ 小于 0.03 的极值点会被舍弃。\n而为了保证关键点的稳定性，仅仅舍弃低对比度的候选点是不够的。高斯差分函数在会产生很强的边缘效应，因此很容易受到噪声的干扰。所以我们也需要剔除掉这些不稳定的边缘点。\n高斯差分函数的相应峰值往往在横跨边缘的地方有较大的的主曲率，而在垂直边缘的地方有较小的主曲率。 主曲率可以通过 $2 \\times 2$ 的 Hessian 矩阵 $\\mathbf{H}$ 来计算：\n$$ \\begin{equation} \\mathbf{H}=\\left[ \\begin{array}{cc}{D_{x x}} \u0026amp; {D_{x y}} \\ {D_{x y}} \u0026amp; {D_{y y}}\\end{array}\\right] % \\label{eq:sift-hessian} \\end{equation} \\tag{4} $$\n其中，导数可以通过相邻样本点的差分来计算。\n$\\mathbf{H}$ 的特征值与 $D$ 的主曲率成正比。设 $\\alpha$ 是最大的特征值，$\\beta$ 是最小的特征值。特征值的总和与乘积可以分别通过 $\\mathbf{H}$ 的迹与行列式来计算：\n$$ \\begin{align*} \\text{Tr}(\\mathbf{H}) \u0026amp;= D_{xx} + D_{yy} = \\alpha + \\beta \\ \\text{Det}(\\mathbf{H}) \u0026amp;= D_{xx}D_{yy} - (D_{xy})^2 = \\alpha\\beta \\end{align*} $$\n如果行列式为负，则该候选点将被舍弃。令 $r$ 为最大特征值与最小特征值的比值，即 $r = \\alpha / \\beta$，则：\n$$ \\frac{\\operatorname{Tr}(\\mathbf{H})^{2}}{\\operatorname{Det}(\\mathbf{H})}=\\frac{(\\alpha+\\beta)^{2}}{\\alpha \\beta}=\\frac{(r \\beta+\\beta)^{2}}{r \\beta^{2}}=\\frac{(r+1)^{2}}{r} $$\n$\\frac{(r + 1)^2}{r}$ 的值在两个特征值相等时最小，并且随着 $r$ 的增大而增大。因此，为了检查主曲率的比值是否低于某个阈值 $r$，只需要判断：\n$$ \\frac{\\operatorname{Tr}(\\mathbf{H})^{2}}{\\operatorname{Det}(\\mathbf{H})}\u0026lt;\\frac{(r+1)^{2}}{r} $$\n这样能够显著提高计算效率。同时我们取经验值 $r = 10$，即排除主曲率之比大于 10 的候选点。\n1.3 方向分配 经过上述两个步骤，我们可以完全找出一幅图像中的特征点，且它们对于尺度具有不变性。而根据局部图像属性为每个关键点指定某个方向，则关键点描述符可以通过该方向来表示，从而实现了旋转不变性。我们根据关键点的尺度选择与之最接近的高斯平滑图像 $L$，以使得所有计算满足了尺度不变性。对该尺度下的每一个图像采样点 $L(x, y)$，我们根据像素值差分来计算其梯度幅值 $m(x, y)$ 和方向 $\\theta(x, y)$：\n$$ \\begin{array}{c} {m(x, y) = \\sqrt{\\left[L(x+1, y)-L(x-1, y)\\right]^{2} + \\left[L(x, y+1)-L(x, y-1)\\right]^{2}}} \\cr\\cr {\\theta(x, y)=\\tan ^{-1}[L(x, y+1)-L(x, y-1)] /[L(x+1, y)-L(x-1, y)]} \\end{array} $$\nSIFT 根据关键点邻域内样本点的梯度方向来生成方向直方图。该直方图一共有 36 柱 (bin)，一柱 $10^{\\circ}$，覆盖整个 $0^{\\circ} \\sim 360^{\\circ}$ 的范围。添加到直方图中的每个样本点梯度方向都会根据其梯度幅值以及圆形高斯加权窗口 (其 $\\sigma$ 为关键点尺度的 1.5 倍) 进行加权。\n方向直方图的峰值对应于关键点局部梯度的主方向。同时，如果直方图中的某一柱的峰值高于其前后两柱，且大于大于主峰值的 80%，则我们在该位置处也创建具有该柱所代表的方向 (可视为辅方向) 的关键点。因此，如果一个方向直方图有很多幅值相近的峰值，那么在其相同尺度和位置处会有很多关键点，但它们的方向有所不同。根据 Lowe 的结论，大概只有 15% 的点被分配了多个方向，但这些方向能够显著提高匹配的稳定性。值得注意的是，每个直方图峰值对应方向是通过对其最接近的三个柱进行抛物线拟合、然后再插值得到的。\n1.4 关键点描述符 之前的步骤已经为每个关键点分配了图像位置、尺度和方向。在图像局部区域内，在图像局部区域内，这些参数可以重复地用以描述局部二维坐标系统，因为这些参数具有不变性。最后一步则是计算局部图像区域的描述符 (local descriptor)，该描述符具有高度的独特性，同时对于光照或 3D 视点的变化具有很高的鲁棒性。\n 图 3 首先通过计算关键点邻域中每个采样点的梯度大小和方向来创建关键点描述符，如左侧所示。计算过程由图像中的原型高斯加权窗口进行加权。然后在邻域范围内创建方向直方图。\n  图 3 展现了描述符的计算方法。首先，根据关键点的尺度选择相同模糊程度的高斯金字塔影像，对关键点邻域内像素进行采样以求得其图像梯度和方向。为了保证特征矢量具有旋转不变性，以关键点为中心，在其邻域内将描述符的坐标轴和梯度方向旋转至关键点的主方向。图 3 左侧图像中的每个小箭头代表该采样点的梯度方向和大小。使用高斯加权函数 ($\\sigma$ 等于描述符窗口宽度 1/2) 来为每个采样点的梯度幅值分配权重，图中圆圈代表窗口范围。\n然后在关键点 $4\\times 4$ 的邻域范围内创建方向直方图。关键点描述符如图 3 中右侧图像所示。每个直方图有八个方向，箭头长度对应与该直方图幅值的大小。该图中显示的是 $2 \\times 2$ 的方向直方图阵列，根据 Lowe 的论文结果，使用 $4 \\times 4$ 的方向直方图阵列，每个直方图有八个方向，可以提高匹配的稳健性。这样对于每个关键点就可以产生 $4 \\times 4 \\times 8 = 128$ 维的特征向量。\n此时的特征向量已经消去了尺度变化、旋转等几何变形因素的影响。最后还需对特征向量进行一定的修正，以进一步降低照明变化的影响。先将特征向量的归一化为单位长度。这样可以使得描述符不收光照仿射变换的影响。而对于非线性光照条件的变化，SIFT 通过对单位特征向量中的值进行阈值化处理，是每个值不大于 0.2 (该值通过实验验证得出)，然后再重新归一化为单位向量。最终得到的这个 128 维的向量即为 SIFT 特征向量。\n1.5 SIFT 匹配方法 SIFT 中的局部特征描述算子对于旋转、尺度缩放和亮度变化保持不变，且对于 3D 视角变化、仿射变换、 噪声等也具有很高的鲁棒性。得到两副目标影像的 SIFT 特征向量之后，我们采用关键点特征向量的欧氏距离作为两幅影像中关键点的相似性判定度量。在左图像中取出某个关键点，并通过遍历找出其与右影像中欧氏距离最接近的两个关键点。如果最邻近关键点与第二邻近关键点距离距离之比低于某个阈值 (经验值为 0.8)，则接受这一对匹配点。\n值得注意的是, 通过调整匹配过程中的阈值，我们可以影响到匹配结果的正确率与匹配点的数量。此外，SIFT 算子对很小的影像或少数几个物体也能产生大量的特征点，而 SIFT 匹配过程中采用了逐关键点遍历的方法, 这在对大尺寸影像处理时有着难以想象的计算开销。\n2. 算法实现-头文件 #pragma once #include \u0026lt;cstdio\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt; using namespace std; using namespace cv; /// 类定义 class SIFT { public: /// 构造函数  SIFT(int nOctaves = 4, int nOctaveLayers = 3, double sigma = 1.6, int nfeatures = 0, double contrastThreshold = 0.04, double edgeThreshold = 10); /// SIFT 类的重载操作符  void operator()(InputArray img, vector\u0026lt;KeyPoint\u0026gt;\u0026amp; keyPoints, OutputArray descriptors); /// 建立高斯金字塔  void buildGaussianPyramid(const Mat\u0026amp; base, vector\u0026lt;Mat\u0026gt;\u0026amp; pyr); /// 建立高斯差分金字塔  void buildGaussianDifferencePyramid(vector\u0026lt;Mat\u0026gt; gauss_pyr, vector\u0026lt;Mat\u0026gt;\u0026amp; dog_pry); /// 尺度空间极值探测  void findScaleSpaceExtrema(vector\u0026lt;Mat\u0026gt;\u0026amp; gauss_pyr, vector\u0026lt;Mat\u0026gt;\u0026amp; dog_pyr, vector\u0026lt;KeyPoint\u0026gt;\u0026amp; keyPoints); protected: int O;\t// 尺度空间数  int S;\t// 每层尺度空间的子层数  double sigma;\t// 尺度空间因子  int nfeatures;\t// 需要输出的特征点数量  double contrastThreshold;\t// 对比度阈值  double edgeThreshold;\t// 边缘阈值 }; /// 宏指令 // 初始图像的尺度，假设为 0.5 （by D.G.Lowe） static const double SIFT_INIT_SIGMA = 0.5; // 描述符数组中每个直方图的柱数 static const int SIFT_DESCR_HIST_BINS = 8; // 在关键点提取中忽略的边缘宽度 static const int SIFT_IMG_BORDER = 5; // 关键点插值的最大迭代次数 static const int SIFT_MAX_INTERP_STEPS = 5; // 方向分配中高斯函数的 σ static const double SIFT_ORI_SIG_FCTR = 1.5; // 方向分配中目标区域的半径 static const double SIFT_ORI_RADIUS = 3 * SIFT_ORI_SIG_FCTR; // 方向分配的梯度直方图柱数（范围为 0 ~ 360°，每 10° 一个柱，共 36 柱） static const int SIFT_ORI_HIST_BINS = 36; // 描述符直方图数组的默认宽度 static const int SIFT_DESCR_WIDTH = 4; // 确定单个描述符方向直方图的大小 static const double SIFT_DESCR_SCL_FCTR = 3.0; // 描述符向量元素大小的阈值 static const double SIFT_DESCR_MAG_THR = 0.2; // 用于将浮点数描述符转换为 uchar 类型 static const double SIFT_INT_DESCR_FCTR = 512; /// 函数声明 // 初始化基层图像矩阵 static Mat createInitialImage(const Mat\u0026amp; img, double _sigma); // 极值点的精确定位 static bool adjustLocalExtrema(const vector\u0026lt;Mat\u0026gt;\u0026amp; dog_pyr, KeyPoint\u0026amp; keyPoint, int octave, int\u0026amp; layer, int\u0026amp; r, int\u0026amp; c, int nOctaveLayers, double contrastThreshold, double edgeThreshold, double _sigma); // 计算关键点局部影像的梯度方向直方图 static double calcOrientationHist(const Mat\u0026amp; img, Point pt, int radius, double _sigma, double* hist, int n); // 关键点特征描述 static void calcSIFTDescriptor(const Mat\u0026amp; img, Point2d kpt, double ori, double scl, int d, int n, double* dst); // 计算特征点描述符 static void calcDescriptors(const vector\u0026lt;Mat\u0026gt;\u0026amp; pyr, const vector\u0026lt;KeyPoint\u0026gt;\u0026amp; keyPoints, Mat\u0026amp; descriptors, int nOctaveLayers); 未完待续…  参考：\n opencv/opencv_contrib/sift.cpp - github D. G. Lowe, Distinctive Image Features from Scale-Invariant Keypoints, International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004. opencv 2.4.9 源码分析 【OpenCV】SIFT原理与源码分析 - 小魏的修行路 - CSDN博客 SIFT算法详解 - zddhub的专栏 - CSDN博客 SIFT: Theory and Practice - AI Shack 张剑清，潘励，王树根，《摄影测量学(第二版)》   ","permalink":"https://jifan.tech/posts/2019-05-10-opencv-4/","summary":"本文及接下来几篇同系列文章是学习 SIFT 算法和 OpenCV SIFT 源码时的学习笔记，整合自参考文献及博客。强烈建议阅读 论文原文、GitHub上的源码 以及 @赵春江 的","title":"OpenCV 源码分析：SIFT 算法原理与实现"},{"content":" 本文主要参考自 OpenCV 官方教程 OpenCV: Camera calibration With OpenCV，大部分内容是对原文的直接翻译。\n 1. 前言 利用手机相机对棋盘图拍摄得到的图像如下所示：\n 图 1 手机相机拍摄图像（左）及其二值化处理后的结果（右）\n  将其与原始棋盘图对比，可以明显地看出，手机拍摄图像出现了一定程度的畸变。\n 图 2 原始图像（左）与二值化处理后的手机拍摄图像（右）对比\n  2. 相机检校原理 目前常用的相机检校方法是附加参数法，其关键在于通过一组额外参数拟合镜头畸变，主要是径向畸变和切向畸变：\n$$ \\begin{align*} dx \u0026amp; = \\overbrace{x(k_1r^2+k_2r^4+k_3r^6)}^{\\text{radial distortion}} + p_1(r^2+2x^2) + p_2xy \\cr dy \u0026amp; = y(k_1r^2+k_2r^4+k_3r^6) + \\underbrace{p_2(r^2+2y^2) + p_1 xy}_{\\text{tangential distortion}} \\end{align*} $$\n式中，\n$$ x=x\u0026rsquo;-x_0, \\newline y=y\u0026rsquo;-y_0, \\newline r^2 = x^2 + y^2 $$\n其中 $(x\u0026rsquo;,y\u0026rsquo;)$ 为像片坐标的原始量测值，$k_i,(i=1,2,3)$ 为径向畸变参数，$p_j, (j=1,2)$ 为切向畸变参数。所以 5 个畸变参数构成的矩阵为：\n$$ \\text{distortion coeffients} = (\\begin{matrix}k_1\u0026amp;k_2\u0026amp;p_1\u0026amp;p_2\u0026amp;k_3\\end{matrix}) $$\n对于影像坐标和物空间坐标的转换关系为：\n$$ \\begin{bmatrix}x \\cr y \\cr f \\end{bmatrix}= K \\begin{bmatrix}X \\cr Y \\cr Z \\end{bmatrix}= \\begin{bmatrix}f_x \u0026amp; 0 \u0026amp; c_x \\cr 0 \u0026amp; f_y \u0026amp; c_y \\cr 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\begin{bmatrix}X \\cr Y \\cr Z \\end{bmatrix} $$\n其中，$(x, y, w)$ 是像点坐标在齐次坐标系下的表示（$w=Z$），$(X,Y,Z)$ 为该点对应的物方坐标。该式有 4 个未知数，$f_x$，$f_y$ 为相机焦距。$c_x$，$c_y$ 为像主点坐标。包含这 4 个参数的矩阵 $K$ 被称为相机矩阵。\n相机检校的过程即是求解相机矩阵和畸变矩阵的过程。这些参数可以通过一些基本的几何方程进行解算，其中使用的公式取决于选择的校准对象，本文所参考的 OpenCV 相机检校方法支持三种类型的校准对象：\n 经典的黑白棋盘图案 对称的圆圈图案 不对称的圆圈图案  为了提高精度、忽略噪声的影像，我们往往需要拍摄多张照片以便进行整体解算。而本回使用的黑白棋盘图案理论上所需的相片数量最多，为此，我一共在不同位置拍摄了 10 张相片（见下图）。\n 图 3 手机相机在不同角度、位置摄影得到 10 张图像\n  3. 检校过程 通过再实现 OpenCV 的相机检校样例，我们主要完成了以下过程：\n 确定畸变矩阵 确定相机矩阵 批量获取影像数据 从 .XML/YAML 文件中读取配置 保存结果到 .XML/YAML 中 计算投影误差  其中，输入的配置文件 input.XML 部分内容如下：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;opencv_storage\u0026gt; \u0026lt;Settings\u0026gt; \u0026lt;!-- 每张检测的棋盘点为 9×6 个 --\u0026gt; \u0026lt;BoardSize_Width\u0026gt; 9\u0026lt;/BoardSize_Width\u0026gt; \u0026lt;BoardSize_Height\u0026gt;6\u0026lt;/BoardSize_Height\u0026gt; \u0026lt;!-- 输入图像的类型，这里我们选择“棋盘图” --\u0026gt; \u0026lt;Calibrate_Pattern\u0026gt;\u0026#34;CHESSBOARD\u0026#34;\u0026lt;/Calibrate_Pattern\u0026gt; \u0026lt;!-- 输入图像，用于相机检校 --\u0026gt; \u0026lt;Input\u0026gt;\u0026#34;inputImages.xml\u0026#34;\u0026lt;/Input\u0026gt; \u0026lt;!-- 输出的日志文件 --\u0026gt; \u0026lt;Write_outputFileName\u0026gt;\u0026#34;out_camera_data.xml\u0026#34;\u0026lt;/Write_outputFileName\u0026gt; \u0026lt;/Settings\u0026gt; \u0026lt;/opencv_storage\u0026gt; 用于检校的输入图像（即上文中的十张相片）通过 inputImages.xml 确定：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;opencv_storage\u0026gt; \u0026lt;images\u0026gt; imgs/IMG_01.jpg imgs/IMG_02.jpg imgs/IMG_03.jpg imgs/IMG_04.jpg imgs/IMG_05.jpg imgs/IMG_06.jpg imgs/IMG_07.jpg imgs/IMG_08.jpg imgs/IMG_09.jpg imgs/IMG_10.jpg \u0026lt;/images\u0026gt; \u0026lt;/opencv_storage\u0026gt; 运行代码，OpenCV 通过 findChessboardCorners() 函数找到每张相片中指定数目的棋盘点 $(9\\times6)$，比如：\n 图 4 findChessboardCorners() 函数在单张相片上的计算结果\n  不过可能是由于光照等因素影响，第八张相片中的点并未成功识别出。程序将尝试在所有输入图像中找到并绘出这些棋盘点：\n 图 5 全部棋盘点识别结果\n  最终我们通过 imwrite() 函数，输出校正变形后的图像：\n 图 6 对相机畸变进行校正后的结果\n  在输出的 out_camera_data.xml 文件中，我们可以得到相机检校过程中的所有参数，包括相机矩阵、畸变参数矩阵和检测点的坐标等。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;opencv_storage\u0026gt; \u0026lt;calibration_time\u0026gt;\u0026#34;Fri Apr 19 14:12:13 2019\u0026#34;\u0026lt;/calibration_time\u0026gt; \u0026lt;nr_of_frames\u0026gt;9\u0026lt;/nr_of_frames\u0026gt; \u0026lt;image_width\u0026gt;900\u0026lt;/image_width\u0026gt;\t\u0026lt;!-- 输入图像宽度 --\u0026gt; \u0026lt;image_height\u0026gt;1200\u0026lt;/image_height\u0026gt;\t\u0026lt;!-- 输入图像高度 --\u0026gt; \u0026lt;board_width\u0026gt;9\u0026lt;/board_width\u0026gt; \u0026lt;board_height\u0026gt;6\u0026lt;/board_height\u0026gt; \u0026lt;square_size\u0026gt;50.\u0026lt;/square_size\u0026gt; \u0026lt;fix_aspect_ratio\u0026gt;1.\u0026lt;/fix_aspect_ratio\u0026gt; \u0026lt;flags\u0026gt;6158\u0026lt;/flags\u0026gt; \u0026lt;fisheye_model\u0026gt;0\u0026lt;/fisheye_model\u0026gt; \u0026lt;camera_matrix type_id=\u0026#34;opencv-matrix\u0026#34;\u0026gt;\t\u0026lt;!-- 相机矩阵 --\u0026gt; \u0026lt;rows\u0026gt;3\u0026lt;/rows\u0026gt; \u0026lt;cols\u0026gt;3\u0026lt;/cols\u0026gt; \u0026lt;dt\u0026gt;d\u0026lt;/dt\u0026gt; \u0026lt;data\u0026gt; 1.1462822465241961e+03 0. 450. 0. 1.1462822465241961e+03 600. 0. 0.1. \u0026lt;/data\u0026gt; \u0026lt;/camera_matrix\u0026gt; \u0026lt;distortion_coefficients type_id=\u0026#34;opencv-matrix\u0026#34;\u0026gt;\t\u0026lt;!-- 畸变矩阵 --\u0026gt; \u0026lt;rows\u0026gt;5\u0026lt;/rows\u0026gt; \u0026lt;cols\u0026gt;1\u0026lt;/cols\u0026gt; \u0026lt;dt\u0026gt;d\u0026lt;/dt\u0026gt; \u0026lt;data\u0026gt; 5.2379099530930096e-01 -4.0406900157339871e+00 0. 0.8.8954798029406810e+00 \u0026lt;/data\u0026gt; \u0026lt;/distortion_coefficients\u0026gt; \u0026lt;avg_reprojection_error\u0026gt;6.1070913167798235e-01\u0026lt;/avg_reprojection_error\u0026gt; \u0026lt;per_view_reprojection_errors type_id=\u0026#34;opencv-matrix\u0026#34;\u0026gt; \u0026lt;rows\u0026gt;9\u0026lt;/rows\u0026gt; \u0026lt;cols\u0026gt;1\u0026lt;/cols\u0026gt; \u0026lt;dt\u0026gt;f\u0026lt;/dt\u0026gt; \u0026lt;data\u0026gt; 7.01961458e-01 6.66437447e-01 5.47557890e-01 5.58410525e-01 4.83857125e-01 5.62040746e-01 6.58297598e-01 6.49597406e-01 6.34681106e-01 \u0026lt;/data\u0026gt; \u0026lt;/per_view_reprojection_errors\u0026gt; \u0026lt;extrinsic_parameters type_id=\u0026#34;opencv-matrix\u0026#34;\u0026gt; \u0026lt;rows\u0026gt;9\u0026lt;/rows\u0026gt; \u0026lt;cols\u0026gt;6\u0026lt;/cols\u0026gt; \u0026lt;dt\u0026gt;d\u0026lt;/dt\u0026gt; \u0026lt;data\u0026gt;\u0026lt;!-- 略 --\u0026gt;\u0026lt;/data\u0026gt; \u0026lt;/extrinsic_parameters\u0026gt; \u0026lt;image_points type_id=\u0026#34;opencv-matrix\u0026#34;\u0026gt; \u0026lt;rows\u0026gt;9\u0026lt;/rows\u0026gt; \u0026lt;cols\u0026gt;54\u0026lt;/cols\u0026gt; \u0026lt;dt\u0026gt;\u0026#34;2f\u0026#34;\u0026lt;/dt\u0026gt; \u0026lt;data\u0026gt;\u0026lt;!-- 略 --\u0026gt;\u0026lt;/data\u0026gt; \u0026lt;/image_points\u0026gt; \u0026lt;grid_points\u0026gt;\u0026lt;!-- 略 --\u0026gt;\u0026lt;/grid_points\u0026gt; \u0026lt;/opencv_storage\u0026gt; 相机矩阵：\n$$ \\begin{align*} \\text{Camera Matrix} \u0026amp;= \\begin{bmatrix} f_x \u0026amp; 0 \u0026amp; c_x \\cr 0 \u0026amp; f_y \u0026amp; c_y \\cr 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\cr \u0026amp;= \\begin{bmatrix} 1146.282 \u0026amp; 0 \u0026amp; 450 \\cr 0 \u0026amp; 1146.282 \u0026amp; 600 \\cr 0 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} \\end{align*} $$\n其中，相机焦距的精确值为 $f_x=f_y=1.1462822465241961e+03$，且 $c_x=450$，$c_y=600$，鉴于输入图像的尺寸为 $900\\times1200$，可以推断出程序直接将图像中心作为像主点。\n畸变矩阵：\n$$ \\begin{align*} \\text{distortion coeffients} \u0026amp;= \\begin{bmatrix}k_1\u0026amp;k_2\u0026amp;p_1\u0026amp;p_2\u0026amp;k_3\\end{bmatrix} \\cr \u0026amp;= \\begin{bmatrix}0.52379 \u0026amp; -4.04069 \u0026amp; 0 \u0026amp; 0 \u0026amp; 8.89548\\end{bmatrix} \\end{align*} $$\n 径向畸变参数的精确值为：  $k_1 = 5.2379099530930096e-01$ $k_2 = -4.0406900157339871e+00$ $k_3 = 8.8954798029406810e+00$   切向畸变参数： $p_1 = p _ 2 = 0$  ","permalink":"https://jifan.tech/posts/2019-04-18-opencv-3/","summary":"本文主要参考自 OpenCV 官方教程 OpenCV: Camera calibration With OpenCV，大部分内容是对原文的直接翻译。 1. 前言 利用手机相机对棋盘图拍摄得到的图像如下所示： 图 1 手机相机拍","title":"OpenCV 相机检校：原理及简单实现"},{"content":"特征值分解 1. 特征值与特征向量 在线性代数中，对于 $n$ 阶方阵 $A$，如果存在某个数 $\\lambda$ 及某个 $n$ 维非零列向量 $v$，使得\n$$ Av = \\lambda v $$\n则称 $\\lambda$ 是方阵 $A$ 的一个特征值，$v$ 是方阵 $A$ 的属于特征值 $\\lambda$ 的一个特征向量。\n对上式进行变换：\n$$ \\begin{align*} Av-\\lambda v \u0026amp;= \\overrightarrow{0} \\cr Av-\\lambda I v \u0026amp;= \\overrightarrow{0} \\cr (A - \\lambda I)v \u0026amp;= \\overrightarrow{0} \\cr (\\lambda I - A)v \u0026amp;= \\overrightarrow{0} \\end{align*} $$\n则称\n $\\lambda E - A$ 为 $A$ 的特征矩阵 行列式 $f(\\lambda) = |\\lambda E- A|$ 为 $A$ 的特征多项式 $|\\lambda E - A| = 0$ 是 $A$ 的特征方程 $(\\lambda E - A)v = \\overrightarrow{0}$ 是 $A$ 关于该特征值 $\\lambda$ 的齐次线性方程组  $A$ 的主对角线上元素之和称为矩阵的迹（trace），记为 $\\text{tr}(A)$，即\n$$ \\text{tr}(A) = a_{11} + a_{22} + \\cdots + a_{nn} $$\n迹和特征值有着很重要的联系：\n$$ \\text{tr}(A) = \\lambda_1 + \\lambda_2 + \\cdots + \\lambda_n $$\n行列式也与特征值有关联：\n$$ |A| = \\lambda_1\\lambda_2\\cdots\\lambda_n $$\n2. 特征值分解 如果我们求出了方阵 $A$ 的 $n$ 个特征值 $\\lambda_1 \\leq \\lambda_2 \\leq \u0026hellip; \\leq \\lambda_n$ 以及这 $n$ 个特征值所对应的特征向量 ${v_1, v_2, \u0026hellip;, v_n}$，且这 $n$ 个特征向量线性无关。那么特征值分解，EVD（Eigen Value Decomposition）就是将方阵 $A$ 用下面的形式表示：\n$$ A = Q \\Sigma Q^{-1} $$\n其中，$Q$ 是这 $n$ 个特征向量组成的 $n \\times n$ 维矩阵，$\\Sigma$ 是以这 $n$ 个特征值为主对角线的 $n \\times n$ 维矩阵。\n若将矩阵 $Q$ 中的 $n$ 个特征向量标准化，即满足 $\\lVert v_i \\rVert_2 = 1$，或者说 $v_i^Tv_i = 1$，此时 $Q$ 中的 $n$ 个特征向量为标准正交基，满足 $Q^TQ = I$，即 $Q^T = Q^{-1}$，此时 $Q$ 是一个酉矩阵。这样我们可以把特征分解表达式写作\n$$ A = Q \\Sigma Q^T $$\n3. 特征值与特征向量的几何意义 从某种意义上将，一个矩阵就是一个线性变换，因为一个矩阵与一个向量相乘的结果，相当于对这个向量进行了线性变换。比如，对于矩阵\n$$ M = \\begin{bmatrix}3 \u0026amp; 0 \\cr 0 \u0026amp; 1\\end{bmatrix} $$\n它对应的线性变换如下图所示：\n 图 1\n  这是因为，矩阵 $M$ 与一个向量 $\\begin{bmatrix} x \u0026amp; y \\end{bmatrix}^T$ 相乘的结果为\n$$ \\begin{bmatrix}3 \u0026amp; 0 \\cr 0 \u0026amp; 1\\end{bmatrix} \\begin{bmatrix}x \\cr y\\end{bmatrix} = \\begin{bmatrix}3x \\cr y\\end{bmatrix} $$\n由于矩阵 $M$ 是对称的，所以这个变换是一个对 $x$、$y$ 轴方向的拉伸变换：每一个对角线上的元素将会对一个维度进行拉伸变换，当值 $\u0026gt; 1$ 时为拉长，值 $\u0026lt; 1$ 时缩短。而当矩阵 $M$ 不对称时\n$$ M = \\begin{bmatrix}1 \u0026amp; 1 \\cr 0 \u0026amp; 1\\end{bmatrix} $$\n它所描述的变换见下图：\n 图 2\n  如蓝色箭头所示，这其实是在平面上对一个轴进行的拉伸变换。图中，蓝色的剪头是一个最主要的变化方向（注意，变化方向并不唯一）。在描述一个变换时，最重要的就是描述这个变换主要的变化方向。\n奇异值分解 奇异值分解，SVD (Singular Value Decomposition) 是线性代数中一种重要的矩阵分解，在信号处理、统计学等领域有重要应用。\n1. 奇异值分解 特征值分解能够得到方阵的特征。对于普通的矩阵，可以采用奇异值分解的方法描述其特征：\n$$ A = U \\Sigma V^T $$\n其中，\n $A$ 是一个 $M \\times N$ 的矩阵 $U$ 是一个 $M \\times M$ 的方阵（$U$ 中的向量称为左奇异向量，都是正交的） $\\Sigma$ 是一个 $M \\times N$ 的矩阵（除了对角线，其他元素都为 0，对角线上的元素称为奇异值） $V$ 是一个 $N \\times N$ 的方阵（$V$ 中的向量称为右奇异向量，都是正交的）  2. 奇异值的计算 将 $A$ 的转置与 $A$ 相乘，那么对于 $N \\times N$ 的方阵 $A^TA$，其特征值及特征向量满足\n$$ (A^TA)v_i = \\lambda_iv_i $$\n其中的 $v_i$ 即右奇异向量，$n$ 个特征向量 $v$ 组成了矩阵 $V$。\n同理，对于 $M \\times M$ 的矩阵 $AA^T$，其特征值和特征向量满足\n$$ (AA^T)u_i = \\lambda_i u_i $$\n其中的 $u_i$ 即左奇异向量，$m$ 个特征向量 $u$ 组成了矩阵 $U$。\n推导可得：\n$$ \\begin{align*} A \u0026amp;= U \\Sigma V^T \\cr AV \u0026amp;= U \\Sigma V^T V \\cr AV \u0026amp;= U \\Sigma \\end{align*} $$\n即\n$$ \\begin{align*} A v_i \u0026amp;= \\sigma_i u_i \\cr \\sigma_i \u0026amp;= Av_i / u_i \\end{align*} $$\n这样可以求得所有的奇异值 $\\sigma$，进而求出奇异值矩阵 $\\Sigma$ 。此外还有\n$$ \\sigma_i = \\sqrt{\\lambda_i} $$\n奇异值 $\\sigma_i$ 也可以通过求出 $A^TA$ 的特征值取平方根得到。\n3. SVD 的性质 奇异值 $\\sigma$ 与特征值类似，在矩阵 $\\Sigma$ 中也是从大到小降序排列，而且 $\\sigma$ 减少得特别快，在很多情况下，前 10% 甚至 1% 的奇异值的和就占全部奇异值之和的 99% 以上了。也就是说，我们也可以用前 $r$ 个奇异值来近似描述矩阵，即部分奇异值分解：\n$$ A_{m\\times n} \\approx U_{m\\times r}\\Sigma_{r \\times r} V^T_{r \\times n} $$\n由于 $r$ 比 $n$ 小很多，存储矩阵和矩阵计算的花费也大大减少。当然，$r$ 越接近于 $n$，相乘的结果也越接近于 $A$ 。\n根据这个性质，SVD 可以用于 PCA（Principal Component Analysis，主成分分析）降维，来做数据压缩和去噪。也可以用于推荐算法，将用户和用户喜好对应的矩阵做特征分解，进而得到隐含的用户需求来做推荐，事实上 Netflix 等公司的推荐算法都采用了 SVD。同时奇异值分解也可以用于 NLP（Natural Language Processing，自然语言处理），比如 LSI（Latent Semantic Indexing，潜在语义索引）等。\nRQ 分解 1. QR 分解 了解 RQ 分解之前，先要掌握 QR 分解。QR 分解将矩阵 $A$ 分解为一个正交矩阵 $Q$ 与上三角矩阵 $R$ 的积，即\n$$ A = QR $$\n使用 Householder 变换可以对其进行求解，此处不再赘述，可参考文末链接。\n2. RQ 分解 对矩阵 $A$ 进行 RQ 分解即将其分解为一个上三角阵 $R$ 与一个正交矩阵（Orthogonal Matrix）$Q$ 的乘积，要求矩阵 $A$ 满秩。\n对于 $n \\times n$ 的矩阵 $A$，若给定矩阵 $P$，满足\n$$ P = \\begin{bmatrix} \u0026amp; \u0026amp; 1 \\cr \u0026amp; \\cdots \u0026amp; \\cr 1 \u0026amp; \u0026amp; \\end{bmatrix} $$\n则 $AP$ 会倒置 $A$ 中列的顺序，$PA$ 会倒置 $A$ 中行的顺序。且 $P^T = P$，$PP = I$，于是 $P^{-1} = P = P^T$，$P$ 为正交矩阵。进行以下步骤的计算：\n 计算 $\\tilde{A} = PA$，即倒置 $A$ 中行的顺序 计算 QR 分解：$\\tilde{A}^T = \\tilde{Q}\\tilde{R}$ 令 $Q = P \\tilde{Q}^T$，即倒置 $\\tilde{Q}^T$ 中行的顺序（$Q$ 是正交矩阵） 令 $R = P\\tilde{R}^TP$  在最后一步中，上三角矩阵 $\\tilde{R}$ 通过两次矩阵 $P$ 相乘变成一个下三角矩阵\n$$ \\begin{bmatrix} * \u0026amp; * \u0026amp; * \\cr \u0026amp; * \u0026amp; * \\cr \u0026amp; \u0026amp; * \\end{bmatrix} \\rightarrow \\begin{bmatrix} \u0026amp; \u0026amp; * \\cr \u0026amp; * \u0026amp; * \\cr * \u0026amp; * \u0026amp; * \\end{bmatrix} \\rightarrow \\begin{bmatrix} * \u0026amp; \u0026amp; \\cr * \u0026amp; * \u0026amp; \\cr * \u0026amp; * \u0026amp; * \\end{bmatrix} $$\n由上面的 $R$ 和 $Q$ 可以得到\n$$ \\begin{align*} RQ \u0026amp;= (P\\tilde{R}^TR)(P\\tilde{Q}^T) = P\\tilde{R}^T\\tilde{Q}^T = P(\\tilde{Q}\\tilde{R})^T \\cr \u0026amp;= P(\\tilde{A}^T)^T=P\\tilde{A}=PPA=A \\end{align*} $$\n  参考：\n$1$. 奇异值分解 - 维基百科，自由的百科全书\n$2$. 机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用 - LeftNotEasy - 博客园\n$3$. AMS :: Feature Column from the AMS\n$4$. 奇异值分解(SVD)原理与在降维中的应用 - 刘建平Pinard - 博客园\n$5$. 奇异值分解（SVD）原理 - JackGao的博客 - CSDN博客\n$6$. QR分解 - 维基百科，自由的百科全书\n$7$. G. H. Golub, C. Reinsch, Singular Value Decomposition and Least Squares Solutions.\n$8$. D. Kalman, A Singularly Valuable Decomposition: The SVD of a Matrix.\n ","permalink":"https://jifan.tech/posts/2019-04-12-linear-algebra-1/","summary":"特征值分解 1. 特征值与特征向量 在线性代数中，对于 $n$ 阶方阵 $A$，如果存在某个数 $\\lambda$ 及某个 $n$ 维非零列向量 $v$，使得 $$ Av = \\lambda v $$ 则称 $\\lambda$ 是方阵 $A$ 的一","title":"线性代数：特征值分解、奇异值分解与 RQ 分解"},{"content":"在计算机视觉（Computer Vision）与摄影测量（Photogrammetry）中，我们在不同影像之间找到相匹配的特征，已建立两幅影像之间的联系，提取出我们所需要的信息。这些特征主要分为：\n 边缘（Edges） 角点（Corners） 兴趣区域 ROI（Regions of Interest）  其中，提取点特征的算子称为兴趣算子或有利算子（Interest Operator），即运用某种算法从影像种提取我们感兴趣的、有利于某种目的的点。\n人眼对角点的识别通常是在一个局部的小区域或小窗口内完成的。如果在各个方向上移动这个特征的小窗口，窗口内区域的灰度发生了较大的变化，那么就认为在窗口内遇到了角点。如果这个特定的窗口在图像各个方面移动时，窗口内图像的灰度没有发生变化，那么窗口内就不存在角点；如果窗口在某一个方向移动时，窗口内图像的灰度发生了较大的变化，而在另一些方向上没有发生变化，那么窗口内的图像可能只是一条直线的线段。\n 图 1 角点\n  角点的特殊之处在于，它是两条边的交点，所以它代表这两条边的方向发生变化的点。因此，图像在该点的梯度（在各个方向上）具有明显的变化。利用这一点，前人提出了一系列算法，其中比较经典的有 Moravec 算子、Forstner 算子以及 Harris 算子等。\nMoravec 算子 基本原理 Moravec 于 1977 年提出利用灰度方差提取点特征的算子，其步骤为：\n1. 计算各像元的兴趣值 $IV$（Interest Value）。 在以像素 $(c, r)$ 为中心的 $w \\times w$ 的窗口中（如 $5 \\times 5$ 的窗口），计算四个方向相邻像素灰度差的平方和：\n$$ \\begin{cases} V_1 = \\sum_{i = -k}^{k-1}(g_{c+i,r}-g_{c+i+1, r})^2 \\cr V_2 = \\sum_{i = -k}^{k-1}(g_{c+i,r+i}-g_{c+i+1, r+i+1})^2 \\cr V_3 = \\sum_{i = -k}^{k-1}(g_{c,r+i}-g_{c+i+1, r+i+1})^2 \\cr V_4 = \\sum_{i = -k}^{k-1}(g_{c+i,r-i}-g_{c+i+1, r-i-1})^2 \\end{cases} $$\n其中 $k = \\text{int}(w/2)$。取其中最小者作为该像素 $(c,r)$ 的兴趣值：\n$$ IV_{c,r} = \\min (V_1,\\ V_2,\\ V_3,\\ V_4) $$\n2. 给定一经验阈值，将兴趣值大于该阈值的点（即兴趣值计算窗口的中心点）作为候选点。 阈值的选择应以候选点中包括所需要的特征点而又不含过多的非特征点为原则。\n3. 选取候选点中的极值点作为特征点。 在一定大小的窗口内（可不同于兴趣值计算窗口，例如 $5 \\times 5$ 像元，$7 \\times 7$ 像元或 $9 \\times 9$ 像元），将候选点中兴趣值不是最大者均去掉，仅留下一个兴趣值最大者，该像素即为一个特征点（有的文献中称此步骤为抑制局部非最大）。\n代码实现 /// Moravec 点特征提取算法 void Moravec(InputArray image, vector\u0026lt;KeyPoint\u0026gt;\u0026amp; keyPoints, int kSize, int threshold) { Mat img; cvtColor(image, img, COLOR_BGR2GRAY); unsigned char* pImg = img.data; int height = img.rows; int width = img.cols; int size = height * width; double* candidatePoints = new double[size]; for (int i = 0; i \u0026lt; size; i++) candidatePoints[i] = 0; int k = kSize / 2; /// I. 计算各像元的兴趣值  for (int i = k; i \u0026lt; height - k; i++) { for (int j = k; j \u0026lt; width - k; j++) { int V1, V2, V3, V4; V1 = V2 = V3 = V4 = 0; // 在以像素 (i, j) 为中心的 k * k 的影像窗口中  // 计算水平、45°、竖直、135°四个方向上相邻像素灰度差的平方和  for (int r = -k; r \u0026lt; k; r++) { V1 += (pImg[(i + r) * width + j] - pImg[(i + r + 1) * width + j]) * (pImg[(i + r) * width + j] - pImg[(i + r + 1) * width + j]); V2 += (pImg[(i + r) * width + j + r] - pImg[(i + r + 1) * width + j + r + 1]) * (pImg[(i + r) * width + j + r] - pImg[(i + r + 1) * width + j + r + 1]); V3 += (pImg[i * width + j + r] - pImg[i * width + j + r + 1]) * (pImg[i * width + j + r] - pImg[i * width + j + r + 1]); V4 += (pImg[(i + r) * width + j - r] - pImg[(i + r + 1) * width + j - r - 1]) * (pImg[(i + r) * width + j - r] - pImg[(i + r + 1) * width + j - r - 1]); } // 取其中的最小值作为该像素 (i, j) 的兴趣值  int value = min(min(V1, V2), min(V3, V4)); // II. 将兴趣值大于阈值的点作为候选点  if (value \u0026gt; threshold) candidatePoints[i * width + j] = value; } } /// III. 选取候选点中的极值点作为特征点（非极大值抑制）  int max_i, max_j, flag; double max_val; for (int i = k; i \u0026lt; height - k; i += kSize) { for (int j = k; j \u0026lt; width - k; j += kSize) { max_i = 0; max_j = 0; max_val = 0; flag = 0; for (int m = -k; m \u0026lt; k; m++) { for (int n = -k; n \u0026lt; k; n++) { double val = candidatePoints[(i + m) * width + j + n]; if (val \u0026gt; max_val) { max_i = i + m; max_j = j + n; max_val = val; flag = 1; } } } if (flag) keyPoints.push_back(KeyPoint((float)max_j, (float)max_i, 2)); } } } 提取结果  图 2 Moravec 算子 输出结果\n  Forstner 算子 基本原理 该算子通过计算各像素的 Robert 梯度和像素 $(c, r)$ 为中心的一个窗口（如 $5 \\times 5)$ 的灰度协方差矩阵，在影像中寻找具有尽可能小而接近圆的误差椭圆的点作为特征点，其步骤为：\n1. 计算各像素的 Robert 梯度。\n$$ \\left.\\begin{matrix} g_u = \\frac{\\partial g}{\\partial u} = g_{i + 1, j + 1} - g_{i, j} \\cr\\cr g_v = \\frac{\\partial g}{\\partial v} = g_{i, j + 1} - g_{i + 1, j} \\end{matrix}\\right\\rbrace $$\n2. 计算 $l \\times l$（如 $5 \\times 5$ 或更大）窗口中灰度的协方差矩阵。\n$$ Q = N^{-1} = \\begin{bmatrix} \\sum g^2_u \u0026amp; \\sum g_ug_v \\cr \\sum g_vg_u \u0026amp; \\sum g^2_v \\end{bmatrix}^{-1} $$\n其中：\n$$ \\begin{align*} \u0026amp;\\sum g_u^2 = \\sum_{i = c - k}^{c+k-1} \\sum_{j=r-k}^{r+k+1}(g_{i+1, j+1} - g_{i,j})^2 \\cr \u0026amp;\\sum g_v^2 = \\sum_{i = c - k}^{c+k-1} \\sum_{j=r-k}^{r+k+1}(g_{i, j+1} - g_{i+1,j})^2 \\cr \u0026amp;\\sum g_ug_v = \\sum_{i = c - k}^{c+k-1} \\sum_{j=r-k}^{r+k+1}(g_{i+1, j+1} - g_{i,j})(g_{i, j+1} - g_{i+1,j}) \\end{align*} $$\n3. 计算兴趣值 $q$ 和 $w$\n$$ \\begin{align*} w \u0026amp;= \\frac{1}{\\text{tr}(Q)} = \\frac{\\det(N)}{\\text{tr}(N)} \\cr q \u0026amp;= \\frac{4\\det(N)}{\\text{tr}(N)^2} \\end{align*} $$\n其中，$\\det(N)$ 代表矩阵 $N$ 的行列式；$\\text{tr}(N)$ 代表矩阵 $N$ 的迹。\n可以证明，$q$ 即像素 $(c, r)$ 对应误差椭圆的圆度：\n$$ q = 1 - \\frac{(a^2-b^2)^2}{(a^2+b^2)^2} $$\n4. 确定待选点。 如果兴趣值大于给定的阈值，则该像元为待选点。阈值为经验值，可参考下列值：\n$$ \\begin{align*} T_q \u0026amp;= 0.5 \\sim 0.75 \\cr T_w \u0026amp;= \\begin{cases} f\\overline{w}\u0026amp;(f=0.5 \\sim 1.5) \\cr cw_c\u0026amp;(c = 5) \\end{cases} \\end{align*} $$\n其中 $\\overline{w}$ 为权平均值；$w_c$ 为权的中值。当 $q \u0026gt; T_q$，且 $w \u0026gt; T_w$ 时，该像元为待选点。\n5. 选取极值点。 以权值 $w$ 为依据选择极值点，即在一个适当窗口中选择最大的待选点，而去掉其余的点。\n代码实现 void Forstner(InputArray image, vector\u0026lt;KeyPoint\u0026gt; \u0026amp; keyPoints, int kSize) { Mat img; cvtColor(image, img, COLOR_BGR2GRAY); unsigned char* pImg = img.data; int height = img.rows; int width = img.cols; int size = height * width; int k = kSize / 2; double grad_u = 0, grad_v = 0;\t// Robert 梯度  double DetN = 0.0, trN = 0.0;\t// DetN: 矩阵 N 的行列式，trN: 矩阵 N 的迹  double weight_total = 0, weight_mean = 0;\t// 权的总值与均值  double q = 0, w = 0;\t// 兴趣值 q、w  double* wPoints = new double[size];\t// 声明存储兴趣值的数组  double* qPoints = new double[size]; for (int i = 0; i \u0026lt; size; i++) {\t// 给数组赋初值  wPoints[i] = 0; qPoints[i] = 0; } for (int i = k; i \u0026lt; height - k; i++) { for (int j = k; j \u0026lt; width - k; j++) { double N[4] = { 0 }; for (int m = -k; m \u0026lt; k; m++) { for (int n = -k; n \u0026lt; k; n++) { grad_u = pImg[(i + m + 1) * width + j + n + 1] - pImg[(i + m) * width + j + n]; grad_v = pImg[(i + m + 1) * width + j + n] - pImg[(i + m) * width + j + n + 1]; N[0] += grad_u * grad_u; N[1] += grad_u * grad_v; N[2] = N[1]; N[3] += grad_v * grad_v; } } DetN = N[0] * N[3] - N[1] * N[2];\t// DetN = determinant(N);  trN = N[0] + N[3];\t// trN = trace(N);  if (trN != 0) { w = DetN / trN;\t// 权  q = 4 * DetN / (trN * trN);\t// 圆度  weight_total += w; wPoints[i * width + j] = w; qPoints[i * width + j] = q; } } } weight_mean = weight_total / size;\t// 权平均值  double Tq = 0.75;\t// 参考阈值  double Tw = 0.5 * weight_mean; for (int i = k; i \u0026lt; height - k; i += kSize) { for (int j = k; j \u0026lt; width - k; j += kSize) { int max_i = 0, max_j = 0, flag = 0; double max_weight = 0; for (int m = -k; m \u0026lt; k; m++) { for (int n = -k; n \u0026lt; k; n++) { double val_q = qPoints[(i + m) * width + j + n]; double val_w = wPoints[(i + m) * width + j + n]; // 大于阈值时，该点为待选点  if ((val_q \u0026gt; Tq) \u0026amp;\u0026amp; (val_w \u0026gt; Tw)) { // 从候选点中选出极值点  if (val_w \u0026gt; max_weight) { max_i = i + m; max_j = j + n; max_weight = val_w; flag = 1; } } } } if (flag)\t// 若有极值点，则存储在 keyPoints 中  keyPoints.push_back(KeyPoint((float)max_j, (float)max_i, 2)); } } } 提取结果 密密麻麻（辣眼睛），感觉效果一般\n 图 3 Forstner 算子输出结果\n  Harris 算子 基本原理 Harris 角点提取算法是 Chris Harris 和 Mike Stephens 在 H.Moravec 算法的基础上发展出的通过自相关矩阵的角点提取算法，又称 Plessey 算法。这种算子受信号处理中自相关函数的启发，给出与自相关函数相联系的矩阵 $M$。$M$ 阵的特征值是自相关函数的一阶曲率，如果两个曲率值都高，那么就认为该点是特征角点。\n对于图像 $I(x, y)$，其在所有方向上位移 $(u, v)$ 后的自相似性可表示为：\n$$ E(u,v) = \\sum_{x,y} \\underbrace{w(x,y)}_{\\text{window function}}\\left[{\\underbrace{I(x+u,y+v)}_{\\text{shifted intensity}}}-\\underbrace{I(x,y)}_\\text{intensity}\\right]^2 $$\n其中窗口函数 $w(x, y)$ 既可以是常数，也可以是高斯函数。\n根据泰勒展开，对图像 $I(x, y)$ 在平移 $(u, v)$ 后进行一阶近似：\n$$ \\begin{align*} I(x+u,y+v) \u0026amp;= I(x, y) + I_x(x, y)u + I_y(x, y)v + O(u^2, v^2) \\cr \u0026amp;\\approx I(x, y) + I_x(x, y)u + I_y(x, y)v \\end{align*} $$\n其中，$I_x$，$I_y$ 是图像 $I(x, y)$ 的偏导数。因此可以推得：\n$$ E(u, v) \\approx \\sum_w[I_x(x, y)u + I_y(x, y)v]^2 = \\begin{bmatrix}u \u0026amp; v\\end{bmatrix} M \\begin{bmatrix} u \\cr v \\end{bmatrix} $$\n其中\n$$ M = \\sum_{x, y} w(x, y) \\begin{bmatrix} I_xI_x \u0026amp; I_xI_y \\cr I_xI_y \u0026amp; I_yI_y\\end{bmatrix} = \\begin{bmatrix}\\sum_{w} I_x^2 \u0026amp; \\sum_{w} I_x I_y \\cr \\sum_{w} I_x I_y \u0026amp; \\sum_{w} I_y^2 \\end{bmatrix} = \\begin{bmatrix}A \u0026amp; C \\cr C \u0026amp; B\\end{bmatrix} $$\n即图像 $I(x, y)$ 在点 $(x, y)$ 处平移 $(u, v)$ 后的自相关函数可以近似为二次项函数：\n$$ E(x, y; u, v) \\approx Au^2 + 2Cuv + Bv^2 $$\n其中\n$$ A = \\sum_{w} I_x^2, \\quad B = \\sum_{w} I_y^2, \\quad C = \\sum_{w} I_xI_y $$\n二次项函数本质上就是一个椭圆函数。椭圆的扁率与尺寸是由 $M(x, y)$ 的特征值 $\\lambda_1$，$\\lambda_2$ 决定的，椭圆的方向是由 $M(x, y)$ 的特征矢量决定的，如下图所示，椭圆方程为：\n$$ \\begin{bmatrix}u \u0026amp; v\\end{bmatrix} M(x, y) \\begin{bmatrix}u \\cr v\\end{bmatrix} = 1 $$\n 图 4 椭圆函数\n  椭圆函数特征值与图像中的角点、直线（边缘）和平面之间的关系如下图所示。共可分为三种情况：\n 图像中的直线。一个特征值大，另一个特征值小，$\\lambda_1 \\gg \\lambda_1$ 或 $\\lambda_2 \\gg \\lambda_1$。自相关函数在某一方向上大，在其他方向上小。 图像中的平面。两个特征值都小，且近似相等。自相关函数数值在各个方向上都小。 图像中的角点。两个特征值都大，且近似相等。自相关函数数值在所有方向上都大。   图 5 椭圆函数特征值与图像中的角点、直线（边缘）和平面之间的关系\n  Harris 算法通过计算角点响应值 $R$ 来判断角点，其计算公式为：\n$$ R = \\det(M)-k(\\text{tr}(M))^2 $$\n式中，$\\det(M)$ 为矩阵 $M = \\begin{bmatrix}A\u0026amp;C \\cr C\u0026amp;B\\end{bmatrix}$ 的行列式；$\\text{tr}(M)$ 为矩阵 $M$ 的直迹；$k$ 为默认常数，取值范围为 $0.04 \\sim 0.06$。事实上，特征是隐含在 $\\det(M)$ 和 $\\text{tr}(M)$ 中的，因为：\n$$ \\begin{align*} \\det(M) = \\lambda_1\\lambda_2 = AB - C^2 \\cr \\text{tr}(M) = \\lambda_1 + \\lambda_2 = A + B \\end{align*} $$\n根绝上述讨论，Harris 角点检测算法的步骤可以总结为：\n1. 计算图像 $I(x, y)$ 在 $x$ 和 $y$ 方向上的梯度 $I_x$、$I_y$：\n$$ \\begin{align*} I_x = \\frac{\\partial I}{\\partial x} = I \\bigotimes (-1 \\ 0 \\ 1), \\cr I_y = \\frac{\\partial I}{\\partial y} = I \\bigotimes (-1 \\ 0 \\ 1)^T \\end{align*} $$\n2. 计算图像两个方向梯度的乘积。\n$$ I_x^2=I_x \\cdot I_x, \\quad I_y^2 = I_y \\cdot I_y, \\quad I_xI_y = I_x \\cdot I_y $$\n3. 使用高斯函数对 $I_x^2$、$I_y^2$ 和 $I_xI_y$ 进行高斯滤波，生成矩阵 $M$ 的元素 $A$、$B$ 和 $C$。 这里，高斯卷积模板的 $\\sigma$ 取 $0.3 \\sim 0.9$。\n$$ A = G(\\tilde{s}) \\bigotimes I_x^2, \\quad B = G(\\tilde{s}) \\bigotimes I_y^2, \\quad C = G(\\tilde{s}) \\bigotimes I_xI_y $$\n4. 计算每个像素的 Harris 响应值 $R$。\n$$ R = \\det(M)-k(\\text{tr}(M))^2 $$\n5. 在 $3 \\times 3$ 或 $5 \\times 5$ 的领域内进行非极大值抑制，局部极值点即为图像中的角点。\n代码实现 void Harris(InputArray image, vector\u0026lt;KeyPoint\u0026gt; \u0026amp; keyPoints) { Mat img = image.getMat(); if (img.channels() == 3) cvtColor(img, img, COLOR_BGR2GRAY); img.convertTo(img, CV_64F); Mat xKernel = (Mat_\u0026lt;double\u0026gt;(1, 3) \u0026lt;\u0026lt; -1, 0, 1); Mat yKernel = xKernel.t(); Mat gX, gY; // filter2D: Convolves an image with the kernel.  filter2D(img, gX, CV_64F, xKernel);\t// x 方向梯度  filter2D(img, gY, CV_64F, yKernel);\t// y 方向梯度  Mat gX2, gY2, gXY; gX2 = gX.mul(gX);\t// gX2 = gX * gX  gY2 = gY.mul(gY);\t// gY2 = gY * gY  gXY = gX.mul(gY);\t// gXY = gX * gY  // getGaussianKernel: Returns Gaussian filter coefficients.  // Aperture size: 7; σ: 0.9  Mat gaussKernel = getGaussianKernel(5, 0.9); // 对梯度值进行高斯滤波  filter2D(gX2, gX2, CV_64F, gaussKernel); filter2D(gY2, gY2, CV_64F, gaussKernel); filter2D(gXY, gXY, CV_64F, gaussKernel); Mat R(img.size(), img.type()); // R: 每个像素的 Harris 响应值  double k = 0.04;\t// k: 默认常数  double detM, trM;\t// det(M): 行列式，tr(M): 迹  for (int i = 0; i \u0026lt; img.rows; i++) { for (int j = 0; j \u0026lt; img.cols; j++) { // 分别计算每个像素的 Harris 响应值  detM = gX2.at\u0026lt;double\u0026gt;(i, j) * gX2.at\u0026lt;double\u0026gt;(i, j) - gXY.at\u0026lt;double\u0026gt;(i, j) * gXY.at\u0026lt;double\u0026gt;(i, j); trM = gX2.at\u0026lt;double\u0026gt;(i, j) + gY2.at\u0026lt;double\u0026gt;(i, j); R.at\u0026lt;double\u0026gt;(i, j) = detM - k * trM * trM; } } double maxStrength;\t// 图像中的最大值  // minMaxLoc: Finds the global minimum and maximum in an array.  minMaxLoc(R, NULL, \u0026amp;maxStrength); Mat dilated, localMax; // dilate: Dilates an image by using a specific structuring element.  // 默认 3 × 3 内核膨胀，膨胀之后除局部最大值与原来相同，其他非局部最大值均被该邻域内的最大值点取代  dilate(R, dilated, Mat()); // compare: Performs the per-element comparison of two arrays or an array and scalar value.  // 与原图相比，找出值相同的（CMP_EQ）点，这些点都是局部最大值点，保存到 localMax 中  compare(R, dilated, localMax, CMP_EQ); Mat cornerMap; double qualityLevel = 0.01; double threshold = qualityLevel * maxStrength; cornerMap = R \u0026gt; threshold; bitwise_and(cornerMap, localMax, cornerMap); // 遍历找出保留的极值点  Mat_\u0026lt;uchar\u0026gt;::const_iterator it = cornerMap.begin\u0026lt;uchar\u0026gt;(); Mat_\u0026lt;uchar\u0026gt;::const_iterator itd = cornerMap.end\u0026lt;uchar\u0026gt;(); for (int i = 0; it != itd; it++, i++) { if (*it) keyPoints.push_back(KeyPoint((float)(i % img.cols), (float)(i / img.cols), 2)); } }  注：在 OpenCV 也有现成的 cornerHarris() 函数计算角点，可以直接调用。\n 提取结果 效果不错，与 Moravec 算子比较接近\n 图 6 Harris 算子输出结果\n   参考：\n$1$. 张剑清，潘励，王树根，《摄影测量学（第二版）》\n$2$. H. P. Moravec, Obstacle Avoidance and Navigation in the Real World by a Seeing Robot Rover, PhD Thesis, Stanford University, Stanford, CA, USA, 1980.\n$3$. OpenCV: Harris Corner Detection\n$4$. Harris角点 - ☆Ronny丶 - 博客园\n ","permalink":"https://jifan.tech/posts/2019-04-02-opencv-2/","summary":"在计算机视觉（Computer Vision）与摄影测量（Photogrammetry）中，我们在不同影像之间找到相匹配的特征，已建立两幅影像","title":"OpenCV 点特征提取算子：Moravec，Forstner 与 Harris"},{"content":"边缘检测（Edge Detection）是图像处理的基础内容。本文中，我从OpenCV官网上下载了最新版本的 OpenCV 4.0.1（2018-12-22），借助官方文档和网络教程完成了环境配置与测试，具体步骤不再赘述。\n在 OpenCV 中可用于边缘检测的算子主要有：\n Canny 算子 Sobel 算子 Laplace 算子  Canny 算子 理论 Canny 算法是由 John F. Canny 于 1987 年在 A computational approach to edge detection 一文提出来的，它旨在满足三个主要标准：\n 低错误率 (Low error rate)：意味着只检测实际存在的边缘。 高定位性 (Good localization)：将检测到的边缘像素与实际边缘像素之间的距离最小化。 最小响应 (Minimal response)：每个边缘只有一个检测器响应。  Canny 算子的步骤如下：\n 滤掉任何噪声。这一过程将使用高斯滤波器。例如，一个 5×5 的高斯内核如下所示：  $$ K = \\dfrac{1}{159} \\begin{bmatrix} 2 \u0026amp; 4 \u0026amp; 5 \u0026amp; 4 \u0026amp; 2 \\cr 4 \u0026amp; 9 \u0026amp; 12 \u0026amp; 9 \u0026amp; 4 \\cr 5 \u0026amp; 12 \u0026amp; 15 \u0026amp; 12 \u0026amp; 5 \\cr 4 \u0026amp; 9 \u0026amp; 12 \u0026amp; 9 \u0026amp; 4 \\cr 2 \u0026amp; 4 \u0026amp; 5 \u0026amp; 4 \u0026amp; 2 \\end{bmatrix} $$\n 计算图像的强度梯度。为此，我们遵循类似于 Sobel 算子的方法：\n  在 $x$ 和 $y$ 方向应用一维卷积掩模：\n$$ G_{x} = \\begin{bmatrix} -1 \u0026amp; 0 \u0026amp; +1 \\cr -2 \u0026amp; 0 \u0026amp; +2 \\cr -1 \u0026amp; 0 \u0026amp; +1 \\end{bmatrix} $$\n$$ G_{y} = \\begin{bmatrix} -1 \u0026amp; -2 \u0026amp; -1 \\cr 0 \u0026amp; 0 \u0026amp; 0 \\cr +1 \u0026amp; +2 \u0026amp; +1 \\end{bmatrix} $$\n  找到梯度强度和方向：\n$$ \\begin{array}{l} G = \\sqrt{ G_{x}^{2} + G_{y}^{2} } \\cr \\theta = \\arctan\\left(\\dfrac{ G_{y} }{ G_{x} }\\right) \\end{array} $$\n将梯度方向四舍五入为四个可能的角度之一（即 0°，45°，90° 或 135°）。\n    非极大值抑制。删除非边缘部分的像素，仅保留作为候选边缘的细线。\n  滞后阈值（Hysteresis）。应用两个阈值（上限 upper 和下限 lower ）：\n 如果像素梯度高于上限，则将其视为边缘 如果像素梯度低于下限，则舍弃 如果像素梯度在两个阈值之间，则仅当它连接到高于上阈值的像素时才将其作为边缘   建议的阈值：$2:1 \\leq upper : lower \\leq 3:1​$\n   应用 OpenCV 中 Canny 函数的用法为：\nvoid cv::Canny(\tinputArray\timage, OutputArray\tedges, double\tthreshold1, double\tthreshold2, int\tapertureSize = 3, bool\tL2gradient = false )  image：输入图像，即源图像，Mat 类单通道8位图像。 edges：输出的边缘图，需要和源图片有一样的尺寸和类型。 threshold1：第一个滞后性阈值。 threshold2：第二个滞后性阈值。 apertureSize：表示应用 Sobel 算子的孔径大小，其有默认值 3。 L2gradient：一个计算图像梯度幅值的标识，有默认值 false。  具体实现：\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;opencv2/core.hpp\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt; using namespace cv; int main() { Mat src, src_gray; src = imread(\u0026#34;lenna.tif\u0026#34;); // 读取图像 \tif( src.empty() ) { printf(\u0026#34;Error: can not open the image.\\n\u0026#34;); return 1; } cvtColor(src, src_gray, COLOR_BGR2GRAY); // Canny 算子 \tMat dst_canny = src.clone(); // 创建图像副本 \tCanny(src, dst_canny, 150, 100); Mat dst_canny_2, edges_canny; dst_canny_2.create(src.size(), src.type()); blur(src_gray, edges_canny, Size(3, 3)); // 用 3×3 内核降噪 \tCanny(edges_canny, edges_canny, 3, 3 * 3, 3); // 运行 Canny 算子 \tdst_canny_2 = Scalar::all(0); // 使用 Canny 算子输出的边缘图 edges_canny 作为掩码， \t// 来将原图 src 拷贝到输出图像 dst_canny_2 中 \tsrc.copyTo(dst_canny_2, edges_canny); imshow(\u0026#34;边缘提取-原图\u0026#34;, src); waitKey(2); imshow(\u0026#34;边缘提取-Canny算子\u0026#34;, dst_canny); waitKey(1); imshow(\u0026#34;边缘提取-Canny算子【高级实现】\u0026#34;, dst_canny_2); waitKey(0); return 0; } 结果如下：  图 1 Canny 算子输出结果\n  Sobel 算子 理论  Sobel 算子是一个离散微分算子。它计算图像强度函数的梯度的近似值。 Sobel 算子结合了高斯平滑和差分。  假设要操作的图像为 $I$：\n  分别计算两个方向的导数：\n  水平变化：将 $I$ 与一个奇数大小（size）的内核 $G_x$ 进行卷积。比如，当内核大小为 3 时，$G_x$ 为：\n$$ G_{x} = \\begin{bmatrix} -1 \u0026amp; 0 \u0026amp; 1 \\cr -2 \u0026amp; 0 \u0026amp; 2 \\cr -1 \u0026amp; 0 \u0026amp; 1 \\end{bmatrix} * I $$\n  垂直变化：将 $I$ 与一个奇数大小（size）的内核 $G_y$ 进行卷积。比如，当内核大小为 3 时，$G_y$ 为：\n$$ G_{y} = \\begin{bmatrix} -1 \u0026amp; -2 \u0026amp; -1 \\cr 0 \u0026amp; 0 \u0026amp; 0 \\cr 1 \u0026amp; 2 \u0026amp; 1 \\end{bmatrix} * I $$\n    在图像的每个点，我们通过组合上面的两个结果来计算该点梯度的近似值：\n$$ G = \\sqrt{ G_{x}^{2} + G_{y}^{2} } $$\n虽然有时会使用以下更简单的公式：\n$$ G = \\left|G_{x}\\right| + \\left|G_{y}\\right| $$\n   注意：\n当内核的大小（size）为 3 时，上述 Sobel 内核可能会有很明显的误差（毕竟 Sobel 算子只是计算导数的近似值）。OpenCV 通过使用 Scharr() 函数解决了大小为 3 的内核存在的这种误差。这比标准 Sobel 函数更快且更准确。具体内核如下：\n$$ G_{x} = \\begin{bmatrix} -3 \u0026amp; 0 \u0026amp; +3 \\cr -10 \u0026amp; 0 \u0026amp; +10 \\cr -3 \u0026amp; 0 \u0026amp; +3 \\end{bmatrix} $$\n$$ G_{y} = \\begin{bmatrix} -3 \u0026amp; -10 \u0026amp; -3 \\cr 0 \u0026amp; 0 \u0026amp; 0 \\cr +3 \u0026amp; +10 \u0026amp; +3 \\end{bmatrix} $$\n 应用 OpenCV 中 Sobel 函数的用法为：\nvoid cv::Sobel( InputArray src, OutputArray dst, int ddepth, int dx, int dy, int ksize = 3, double scale = 1, double delta = 0, int borderType = BORDER_DEFAULT )\t  src：输入图像\n  dst：与 src 具有相同大小和相同通道数的输出图像\n  ddepth：输出图像的深度，支持如下 src.depth() 和 ddepth 的组合：\n   Input depth (src.depth()) Output depth (ddepth)     CV_8U -1 / CV_16S / CV_32F / CV_64F   CV_16U / CV_16S -1 / CV_32F / CV_64F   CV_32F -1 / CV_32F / CV_64F   CV_64F -1 / CV_64F      dx：x 方向上的差分阶数。\n  dy：y 方向上的差分阶数。\n  ksize：Sobel 内核的大小；必须取 1，3，5 或 7。\n  scale：计算导数值时可选的缩放因子，默认值是1，表示默认情况下是没有应用缩放的。\n  delta：表示在结果存入 dst 之前可选的 delta 值。\n  borderType：边界模式，默认值为BORDER_DEFAULT。详见 BorderTypes。\n  因为 Sobel 算子结合了高斯平滑和差分，因此会具有更多的抗噪性。\n具体实现：\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;opencv2/core.hpp\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt; using namespace cv; int main() { Mat src = imread(\u0026#34;lenna.tif\u0026#34;);\t// 读取图像 \tif( src.empty() ) { printf(\u0026#34;Error: can not open the image.\\n\u0026#34;); return 1; } Mat src_blur, src_blur_gray, dst_sobel; // 高斯滤波器去噪（kernel size = 3） \tGaussianBlur(src, src_blur, Size(3, 3), 0, 0, BORDER_DEFAULT); // 将图像转换为灰度图像 \tcvtColor(src_blur, src_blur_gray, COLOR_BGR2GRAY); Mat grad_x, grad_y; Mat abs_grad_x, abs_grad_y; // 分别求 X、Y 方向梯度 \tSobel(src_blur_gray, grad_x, CV_16S, 1, 0, 3, 1, 1, BORDER_DEFAULT);\tSobel(src_blur_gray, grad_y, CV_16S, 0, 1, 3, 1, 1, BORDER_DEFAULT); // 转换回 CV_8U \tconvertScaleAbs(grad_x, abs_grad_x); convertScaleAbs(grad_y, abs_grad_y); // 合并梯度 \taddWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0, dst_sobel); imshow(\u0026#34;边缘提取-原图\u0026#34;, src); waitKey(3); imshow(\u0026#34;边缘提取-Sobel算子-X方向\u0026#34;, abs_grad_x); waitKey(2); imshow(\u0026#34;边缘提取-Sobel算子-Y方向\u0026#34;, abs_grad_y); waitKey(1); imshow(\u0026#34;边缘提取-Sobel算子-整体方向\u0026#34;, dst_sobel); waitKey(0); return 0; }  图 2 Sobel 算子输出结果\n  Laplace 算子 理论   根据数字图像处理相关知识，我们知道二阶导数可用于检测边缘。由于图像是二维（2D）的，我们需要在两个方向上进行求导。\n  Laplace 算子定义为：\n$$ Laplace(f) = \\dfrac{\\partial^{2} f}{\\partial x^{2}} + \\dfrac{\\partial^{2} f}{\\partial y^{2}} $$\n  在 OpenCV 中，Laplace 算子通过函数 Laplacian() 实现。实际上，由于拉普拉斯算子利用了图像的梯度，因此它在内部调用 Sobel 算子来执行其运算，\n  应用 OpenCV 中 Laplacian() 函数的用法为：\nvoid cv::Laplacian( InputArray src, OutputArray dst, int ddepth, int ksize = 1, double scale = 1, double delta = 0, int borderType = BORDER_DEFAULT )\t src：输入图像 dst：与 src 具有相同大小和相同通道数的输出图像 ddepth：输出图像的深度。 ksize：用于计算二阶导数的滤波器的孔径尺寸；它可以是 FILTER_SCHARR、1、3、5 或 7。 scale：计算拉普拉斯值时可选的比例因子，默认值是1，表示默认情况下是没有应用缩放的。 delta：表示在结果存入 dst 之前可选的 delta 值。 borderType：边界模式，默认值为BORDER_DEFAULT。详见 BorderTypes。  Laplacian() 函数主要利用 Sobel 算子进行运算。它通过加上 Sobel 算子运算出的图像 $x$ 方向和 $y$ 方向上的导数，来得到输入图像的拉普拉斯变换结果。当 ksize == 1 时，拉普拉斯函数的滤波窗口为：\n$$ \\begin{bmatrix} 0 \u0026amp; 1 \u0026amp; 0 \\cr 1 \u0026amp; -4 \u0026amp; 1 \\cr 0 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix} $$\n具体实现：\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;opencv2/core.hpp\u0026gt;#include \u0026lt;opencv2/opencv.hpp\u0026gt; using namespace cv; int main() { // 读取图像 \tMat src = imread(\u0026#34;lenna.tif\u0026#34;);\tif( src.empty() ) { printf(\u0026#34;Error: can not open the image.\\n\u0026#34;); return 1; } // Laplace 算子 \tMat src_blur, src_blur_gray; Mat dst_laplace, abs_dst_laplace; // 高斯滤波器去噪（kernel size = 3） \tGaussianBlur(src, src_blur, Size(3, 3), 0, 0, BORDER_DEFAULT); // 将图像转换为灰度图像 \tcvtColor(src_blur, src_blur_gray, COLOR_BGR2GRAY); // 应用 Laplace 算子 \tLaplacian(src_blur_gray, dst_laplace, CV_16S, 3, 1, 0, BORDER_DEFAULT); // 计算绝对值，将结果转换为 8 位 \tconvertScaleAbs(dst_laplace, abs_dst_laplace); imshow(\u0026#34;边缘提取-原图\u0026#34;, src); waitKey(1); imshow(\u0026#34;边缘检测-Laplace算子\u0026#34;, abs_dst_laplace); waitKey(0); return 0; }  图 3 Laplace 算子输出结果\n   参考：\n 【OpenCV入门教程之十二】OpenCV边缘检测 - 毛星云（浅墨）的专栏 - CSDN博客 OpenCV: Image Filtering OpenCV: Image Processing (imgproc module) OpenCV: Canny Edge Detector OpenCV: Sobel Derivatives OpenCV: Laplace Operator   ","permalink":"https://jifan.tech/posts/2019-03-19-opencv-1/","summary":"边缘检测（Edge Detection）是图像处理的基础内容。本文中，我从OpenCV官网上下载了最新版本的 OpenCV 4.0.1（2018-12-22","title":"OpenCV 内置边缘检测算子：Canny，Sobel 与 Laplace"},{"content":"斐波那契数列 斐波那契数列（Fibonacci Sequence）是一串数字：\n\\[ (0,)\\ 1,\\ 1,\\ 2,\\ 3,\\ 5,\\ 8,\\ 13,\\ 21,\\ 34,\\ 55,\\ 89,\\ 144,\\ \u0026hellip; \\] 很容易看出，每一个数（除第 1、2 个）都等于它之前的两个数之和。因此，用公式可归纳为： \\[ F_n = \\begin{cases} 0, \u0026amp; n=0 \\\\ 1, \u0026amp; n=1 \\\\ F_{n-1} + F_{n-2}, \u0026amp; n\u0026gt;1 \\end{cases} \\]\n计算复杂性理论 在将斐波那契数列用 C++ 代码实现并计算时间、空间复杂度之前，先要了解一下什么是所谓的“复杂度”\n时间复杂度  在计算机科学中， 算法的时间复杂度（Time Complexity）是一个函数，它定性描述算法的运行时间。这是一个代表算法输入值的字符串的长度的函数。\n引自：Wikipedia，时间复杂度\n 一个语句的频度是指该语句在算法中被重复执行的次数。算法中所有语句的频度之和即为 $T(n)$，它是该算法问题规模 $n$ 的函数，时间复杂度主要分析 $T(n)$ 的数量级。 算法的基本运算（最深层循环内的语句）的频度与 $T(n)$ 同数量级。因此通常采用算法中基本运算的频度 $f(n)$ 来分析算法的时间复杂度。因此，算法的时间复杂度记为：\n\\[ T(n) = O(f(n)) \\]\n式中，$O$ 的含义是 $T(n)$ 的数量级，其严格的数学定义是：若 $T(n)$ 和 $f(n)$ 是定义在正整数集合上的两个函数，则存在正常数 $C$ 和 $n_0$，使得当 $n \\geq n_0$ 时，都满足 $0 \\leq T(n) \\leq Cf(n)$。\n算法的时间复杂度不仅依赖于问题的规模 $n$，也去决定于待输入数据的性质（如输入数据元素的初始状态）。\n 最坏时间复杂度：在最坏情况下，算法的时间复杂度。 平均时间复杂度：所有可能输入示例在等概率出现的情况下，算法的期望运行时间。 最好时间复杂度：在最好情况下，算法的时间复杂度。  一般总是考虑在最坏情况下的时间复杂度，以保证算法的运行时常不会比它更长。\n在分析一个程序的时间复杂性时，有以下两条规则：\n(a) 加法规则： \\[ \\begin{align*} T(n) \u0026amp;= T_1\\left(n\\right) + T_2\\left(n\\right) \\cr \u0026amp;= O\\left(f\\left(n\\right)\\right) + O(g(n)) \\cr \u0026amp;= O\\left(\\max(f(n), g(n))\\right) \\end{align*} \\] (b) 乘法规则： \\[ \\begin{align*} T(n) \u0026amp;= T_1(n) \\times T_2(n) \\cr \u0026amp;= O(f(n)) \\times O(g(n)) \\cr \u0026amp;= O(f(n) \\times g(n)) \\end{align*} \\] 时间复杂度可被成为是渐进的，亦即考察输入值大小趋近于无穷时（$n\\rightarrow\\infty$）的情况。 常见的渐进时间复杂度为： \\[ O(1) \u0026lt; O(\\log_2 n) \u0026lt; O(n) \u0026lt; O(n\\log_2 n) \u0026lt; O(n^2) \\newline \u0026lt; O(n^3) \u0026lt; O(2^n) \u0026lt; O(n!) \u0026lt; O(n^n) \\]\n空间复杂度  算法的空间复杂度 $S(n)$ 被定义为该算法所耗费的存储空间，它是问题规模 $n$ 的函数。渐进空间复杂度也常简称为空间复杂度，记为 $S(n) = O(g(n))$。\n 一个程序除需要存储空间来存放本身所用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储为实现计算机所需的一些信息的辅助空间，若输入数据所占空间只取决于问题本身而与算法无关，则只需分析除输入和程序外的额外空间。\n算法原地工作是指算法所需的辅助空间为常量，即 $O(1)$。\n递归算法 最简单的算法即是根据定义写出的递归算法，C++ 代码如下：\nint fibonacci(int n) { if (n \u0026lt; 2) { return n; } return fibonacci(n - 1) + fibonacci(n - 2); } 时间复杂度：\n我们知道斐波那契数列数列的递归方程是 $T(n) = T(n-1) + T(n-2) + O(1)$。这就意味着，计算 fibonacci(n) 的时间等于计算 fibonacci(n-1) 与 fibonacci(n-2) 的时间。因此我们很容易得知，在递归求解斐波那契数时，时间复杂度的上界 (upper bound) 是 $O(2^n)$。但通过在数学上用线性递归函数来表示，我们可以找到 Fibonacci 的上确界 (tight upper bound or supremum)。\n现根据斐波那契数列的定义： \\[ F(n) = F(n-1) + F(n-2) \\] 得到其特征方程为： \\[ x^2 = x + 1 \\newline x^2 - x - 1 = 0 \\] 解得该二次方程的根为 $\\alpha_1 = \\frac{1 + \\sqrt{5}}{2},\\ \\alpha_2 = \\frac{1 - \\sqrt{5}}{2}$。现在我们得到的线性递归函数为： \\[ F(n) = (\\alpha_1)^n + (\\alpha_2)^n \\] 所以斐波那契函数 $F(n) = F(n-1) + F(n-2)$ 的解为： \\[ F(n) = (\\frac{1 + \\sqrt{5}}{2})^n + (\\frac{1 - \\sqrt{5}}{2})^n \\] 显然，在进行无穷大（$n \\rightarrow \\infty$）渐进分析 时，$T(n)$ 与 $F(n)$ 表示含义是相同的，可被近似地看做相等，于是可以得出： \\[ T(n) = O\\left(\\left(\\frac{1 + \\sqrt{5}}{2}\\right)^n + \\left(\\frac{1 - \\sqrt{5}}{2}\\right)^n\\right) \\] 或者可以写作如下形式 （根据渐进符号 $O$ (Big O notation)，可以忽略掉低阶项）： \\[ T(n) = O((\\frac{1 + \\sqrt{5}}{2})^n) \\\\\\\\ T(n) = O(1.618^n) \\] 这即是斐波那契递归函数的上确界（tight upper bound），同时我们也可以知道，递归算法确切的时间复杂度为 $O(1.618^n)$。\n空间复杂度：函数每次执行都会调用一次堆栈，故空间复杂度为 $O(n)$。\n循环算法 循环算法的思路为：\n 当 $n = 0$ 时，返回 $F_0$ 的值 $0$（此时，$F_{n+1}=F_1=1$，$F_n=F_0=0$ 的值已给出 当 $n \u0026gt; 0\\ (1,\\ 2,\\ \u0026hellip;,\\ \\infty)$ 时  用一个数 b 存放 $F_n$ 的值，另一个数 a 存放 $F_{n+1}$ 的值 执行一次循环，a + b 为新的 $F_{n+1}$ 的值，原有的 a 的值即为新的 $F_n$，再将这两个值分别赋给两个对应的变量（temp 充当媒介） 按此往复，直到循环结束    int fibonacci(int n) { int a = 1, b = 0, temp; while (n \u0026gt; 0) { temp = a; a = a + b; b = temp; n--; } return b; } 时间复杂度：思路很清晰，循环次数与 $n$ 线性正相关，时间复杂度为 $O(n)$，较之递归算法好很多。\n空间复杂度：算法所需要的辅助空间为常量，故空间复杂度为 $O(1)$。\n尾递归算法 尾递归算法的思路与循环算法相似，调用格式为 fibonacci(0, 1, n) ：\nint fibonacci(int first, int second, int n) { if (n \u0026lt; 2) { return n; } else if (n == 2) { return first + second; } return fibonacci(second, first + second, n - 1); } 时间复杂度：递归次数为 $n$，故为 $O(n)$。\n空间复杂度：函数每一次执行都会调用一次堆栈，故为 $O(n)$。\n矩阵算法 比较上述几种算法，可以看出，它们都利用了分治 (divide and conquer) 的思想——将原问题划分成若干个规模较小而结构与原问题相同或相似的子问题，然后分别解决这些子问题，最后合并子问题的解，即可得到为原问题的解。只不过区别在于是进行普通地分治还是动态规划。\n我们将斐波那契数列中相邻的两项 $F(n)$ 和 $F(n-1)$ 写成一个 $2 \\times 1$ 的矩阵，通过计算可以得到以下结论： \\[ \\begin{bmatrix} F_n \\cr F_{n-1} \\end{bmatrix} = \\begin{bmatrix} F_{n-1} + F_{n-2} \\cr F_{n-1} \\end{bmatrix} = \\begin{bmatrix} 1 \\times F_{n-1}+1 \\times F_{n-2} \\cr 1 \\times F_{n-1}+0 \\times F_{n-2} \\end{bmatrix} = \\begin{bmatrix}1\u0026amp;1 \\cr 1\u0026amp;0 \\end{bmatrix}\\times\\begin{bmatrix}F_{n-1} \\cr F_{n-2}\\end{bmatrix} \\] 推得： \\[ \\begin{bmatrix}F_n \\cr F_{n-1} \\end{bmatrix} =\\begin{bmatrix}1\u0026amp;1 \\cr 1\u0026amp;0 \\end{bmatrix}^{n-1} \\times \\begin{bmatrix}F_{1} \\cr F_{0} \\end{bmatrix} =\\begin{bmatrix}1\u0026amp;1 \\cr 1\u0026amp;0 \\end{bmatrix}^{n-1} \\times \\begin{bmatrix}1 \\cr 0 \\end{bmatrix} \\] 因此要求斐波那契数 $F(n)$，关键是计算二阶矩阵 $\\begin{bmatrix}1\u0026amp;1\\\\1\u0026amp;0\\end{bmatrix}$ 的 $n - 1$ 的次方。最终取相乘结果矩阵第一行第一列数字即可。\n求方阵的 $n-1$ 次方乍一看非常繁复，而且要求这么多次的乘方，时间复杂度也为 $O(n)$，相较于循环算法没有进步。 那么，为什么我们还要讨论这个方法呢？因为幂运算是可以通过二分幂来优化加速的。比如说，当我们需要计算 $a^n$ 时： \\[ a^n=\\begin{cases} a^{\\frac{n}{2}}\\times a^{\\frac{n}{2}}\u0026amp;,\\text{ if $x$ is even} \\cr a^{\\frac{n-1}{2}}\\times a^{\\frac{n-1}{2}}\\times a\u0026amp;,\\text{ if $x$ is odd} \\end{cases} \\] 这个方法也运用了分治的思想，节省了大约 $n/2 - 1$ 次乘法运算。那么时间复杂度也由原来的 $O(n)$ 降低为 $O(\\log n)$。\n算法的 C++ 代码如下：\nvoid multiply(int F[2][2], int M[2][2]);\t// 计算矩阵 F×M void power(int F[2][2], int n);\t// 求矩阵 F 的 n 次方  int fibonacci(int first, int second, int n) { int F[2][2] = { {1, 1}, {1, 0} }; if (n == 0) return 0; power(F, n - 1); // 计算目标二阶矩阵的 n - 1 次方  return F[0][0]; } void multiply(int F[2][2], int M[2][2]) { int x = F[0][0] * M[0][0] + F[0][1] * M[1][0]; int y = F[0][0] * M[0][1] + F[0][1] * M[1][1]; int z = F[1][0] * M[0][0] + F[1][1] * M[1][0]; int w = F[1][0] * M[0][1] + F[1][1] * M[1][1]; F[0][0] = x; F[0][1] = y; F[1][0] = z; F[1][1] = w; } void power(int F[2][2], int n) { if (n == 0 || n == 1) return; int M[2][2] = { {1, 1}, {1, 0} }; power(F, n / 2); // 二分幂方法  multiply(F, F); if (n % 2 != 0) multiply(F, M); } 时间复杂度：$O(\\log n)$。\n空间复杂度：算法所需的辅助空间仍为常量（虽然可能相对较大），故为 $O(1)$。\n  参考：\n$1.$ 斐波那契数的时间复杂度、空间复杂度详解 - lxf_style的博客 - CSDN博客\n$2.$ Fibonacci Sequence - MathIsFun.com\n$3.$ Fibonacci sequence algorithm in Javascript – Developers Writing – Medium\n$4.$ 计算斐波纳契数，分析算法复杂度 · GoCalf Blog\n$5.$ Time complexity of recursive Fibonacci program - GeeksforGeeks\n$6.$ Program for Fibonacci numbers - GeeksforGeeks\n$7.$ 二分幂，快速幂，矩阵快速幂，快速乘 - 丁磊_ml的博客 - CSDN博客\n ","permalink":"https://jifan.tech/posts/2019-03-01-ds-notes-1/","summary":"斐波那契数列 斐波那契数列（Fibonacci Sequence）是一串数字： \\[ (0,)\\ 1,\\ 1,\\ 2,\\ 3,\\ 5,\\ 8,\\ 13,\\ 21,\\ 34,\\ 55,\\ 89,\\ 144,\\ \u0026hellip; \\] 很容易看出，每一个数（除第 1、2 个","title":"数据结构笔记：求解斐波那契数列算法的复杂度"},{"content":" 再一次地、从头开始学习C/C++。\n C++ 数据类型及其表示范围 这一部分是基础，不过我之前都没有系统性的搞清楚，所以现在还是先把这些知识点列出来，该部分参考C++ 数据类型 - 菜鸟教程。\n1. 基本的内置类型 C++ 为程序员提供了种类丰富的内置数据类型和用户自定义的数据类型。下表列出了七种基本的 C++ 数据类型：\n   类型 关键字     布尔型 bool   字符型 char   整型 int   浮点型 float   双浮点型 double   无类型 void   宽字符型 wchar_t    其中，wchar_t 实际上是：\ntypedef wchar_t short int; 所以 wchar_t 实际上的空间和 short int 一样。 一些基本类型可以使用一个或多个类型修饰符进行修饰：\n signed unsigned short long  2. 各种变量类型的大小    数据类型 字节数 表示范围     char 1 $-128 \\sim 127 \\ ||\\ 0 \\sim 255$   unsigned char 1 $0 \\sim 255$   signed char 1 $-128 \\sim 127$   int 4 $-2^{31} \\sim 2^{31}-1$   unsigned int 4 $0 \\sim 2^{32} - 1$   signed int 4 $-2^{31} \\sim 2^{31}-1$   short int 2 $-2^{15} \\sim 2^{15}-1$   unsigned short int 2 $0 \\sim 2^{16} - 1$   signed short int 2 $-2^{15} \\sim 2^{15}-1$   long int 8 $-2^{63} \\sim 2^{63} - 1$   unsigned long int 8 $0 \\sim 2^{64} - 1$   signed long int 8 $-2^{63} \\sim 2^{63} - 1$   float 4 $-3.40 \\times 10^{38} \\sim 3.40 \\times 10^{38}$   double 8 $-1.79\\times10^{308} \\sim 1.79 \\times 10^{308}$    注：不同系统可能会有所差异。\n浮点数的比较  在学习《算法笔记》一书时，作者介绍了“极小数”用以修正浮点数在计算机中存储与计算产生的误差。这一点是我在之前学习中所没有意识到的，于是在此归纳一下相关的内容。\n 由于计算机中采用有限位的二进制编码，因此浮点数在计算机中的存储并不总是精确的。例如在经过大量运算后，一个浮点型的数 3.14 在计算机中就可能存储成 3.1400000000001，也有可能存储成 3.1399999999999，这种情况下会对比较操作带来极大的干扰（因为C/C++中的 == 操作是完全相同才能判定为 true）。于是在文中，作者引入了一个极小数 eps 来对这种误差进行修正。\n经验表明，eps 取 $1e-8$（$10^{-8}$） 在大多数情况下既不会漏判，也不会误判。因此可将 eps 定义为常量 $1e-8$：\nconst double eps = 1e-8; 1. 等于运算符 == 下图为等于区间示意图：\n 图 1 等于区间示意图\n  如图所示，如果一个数 a 落在了 $[b - eps, b + eps]$ 的区间中，就判断 a == b 成立。为了使比较更为方便，把比较操作写成宏定义的形式：\n#include \u0026lt;math.h\u0026gt;#define Equ(a, b) ((fabs((a) - (b))) - (eps)) // 括号是为防止宏定义可能带来的错误 2. 大于运算符 \u0026gt; 下图为大于区间示意图：\n 图 2 大于区间示意图\n  如图所示，如果一个数 a 要大于 b，那么就必须在误差 eps 扰动范围之外大于 b，因此只有大于 b + eps 的数才能判定为大于 b（也即 $a - b \u0026gt; eps$）。\n#define More(a, b) (((a) - (b)) \u0026gt; (eps)) 3. 小于运算符 \u0026lt; 下图为小于区间示意图：\n 图 3 小于区间示意图\n  如图所示，如果一个数 a 要小于 b，那么就必须在误差 eps 扰动范围之外小于 b，因此只有小于 b - eps 的数才能判定为小于 b（也即 $a - b \u0026lt; -eps$）。\n#define Less(a, b) (((a) - (b)) \u0026lt; (-eps)) 4. 大于等于运算符 \u0026gt;= 下图为大于等于区间示意图：\n 图 4 大于等于区间示意图\n  如图所示，由于大于等于运算符可以理解为大于运算符和等于运算符的结合，于是需要让一个数 a 在误差扰动范围内大于或者等于 b，因此大于 b - eps 的数都应当判定为大于等于 b（也即 $a - b \u0026gt; -eps$）。\n#define MoreEqu(a, b) (((a) - (b)) \u0026gt; (-eps)) 5. 小于等于运算符 \u0026lt;= 下图为小于等于区间示意图：\n 图 5 小于等于区间示意图\n  如图所示，由于小于等于运算符可以理解为小于运算符和等于运算符的结合，于是需要让一个数 a 在误差扰动范围内小于或者等于 b，因此小于 b + eps 的数都应当判定为小于等于 b（也即 $a - b \u0026lt; eps$）。\n#define LessEqu(a, b) (((a) - (b)) \u0026lt; (eps)) 6. 圆周率 π 圆周率 π 可由 $arccos(-1)$ 计算得到：\n#include \u0026lt;math.h\u0026gt;const double PI = acos(-1.0); 汇总结果为如下代码：\n#include \u0026lt;math.h\u0026gt;const double eps = 1e-8; const double PI = acos(-1.0); #define Equ(a, b) ((fabs((a) - (b))) - (eps)) #define More(a, b) (((a) - (b)) \u0026gt; (eps)) #define Less(a, b) (((a) - (b)) \u0026lt; (-eps)) #define MoreEqu(a, b) (((a) - (b)) \u0026gt; (-eps)) #define LessEqu(a, b) (((a) - (b)) \u0026lt; (eps)) 读取“大数” 有的时候，我需要读入一个很大的整数（例如，1234567890987654321123456789），并计算出它的各位数字之和。用 int ($-2^{31} \\sim 2^{31} - 1$) 或者 long int ($-2^{63} \\sim 2^{63} - 1$) 都不满足要求。这时可以将这样一个“大数”作为字符串（或是字符数组）读入。\n 字符串实际上是使用 null 字符 '\\0' 终止的一维字符数组。因此，一个以 null 结尾的字符串，包含了组成字符串的字符。\n 我们可以使用 getchar() 函数，将该数字的每一位作为字符读入到我们的字符串数组中。\n C 库函数 int getchar(void) 从标准输入 stdin 获取一个字符（一个无符号字符）。这等同于 getc 带有 stdin 作为参数。\n 用程序可以简单地表示为：\n#include \u0026lt;stdio.h\u0026gt; int main() { char n[100]; int i = 0; printf(\u0026#34;Input: \u0026#34;); while ((n[i] = getchar()) != \u0026#39;\\n\u0026#39;) { // 逐位读入数字  i++; } printf(\u0026#34;Output: \u0026#34;); for (int k = 0; k \u0026lt; i; k++) { printf(\u0026#34;%c\u0026#34;, n[k]); // 逐位输出数字  } printf(\u0026#34;\\n\\n\u0026#34;); return 0; } 当我们输入数字 1234567890987654321123456789，也会得到相应的输出：\n 图 6 输出结果\n  此时，存储字符的数组 n 为：\n 图 7 字符数组在内存中的值\n  ","permalink":"https://jifan.tech/posts/2019-02-27-cpp-study-notes-1/","summary":"再一次地、从头开始学习C/C++。 C++ 数据类型及其表示范围 这一部分是基础，不过我之前都没有系统性的搞清楚，所以现在还是先把这些知识点列出来，该","title":"C++ 学习笔记：数据类型、浮点数的比较以及“大数”的读取"},{"content":"Yes, indeed. This is not my first blog. You may find that there are some posts publised in quite a few years ago, followed by a long gap. Perhaps there will be an opportunity to tell you the story of that time ……\n1. My Previous Blogs 1.1 A taste of WordPress WordPress was, and probably still is, the most popular blog hosting platform in the world. It\u0026rsquo;s almost entirely code-free to start a blog with WordPress. Unfortunately, I wasn\u0026rsquo;t an enthusiastic blogger then, so this product of a whim was left unused as soon as it was built.\n Figure 1. My first but empty blog\n  1.2 Blogging with Jekyll on a NGINX Server By the time I rediscovered my passion for blogging, Jekyll, as a static site generator, has already caught on. Detailed documentation, rich themes, and an active community were my reasons for choosing it.\nAfter installing the prerequisites, the entire setup process can be divided into 3 poarts.\n Server setting:  Nginx installation, configuration and deployment. server { listen 80 ; server_name _ localhost my-thistledown.com www.my-thistledown.com ; location = /webhook { proxy_pass http://127.0.0.1:3001/webhook; } # return 301 https://www.my-thistledown.com$request_uri; } server { listen 443; server_name my-thistledown.com; return 301 https://www.my-thistledown.com$request_uri; } server { listen 443 default_server ssl; server_name www.my-thistledown.com; ssl on; ssl_certificate /etc/nginx/ssl/my-thistledown.com/1692217_my-thistledown.com.pem; ssl_certificate_key /etc/nginx/ssl/my-thistledown.com/1692217_my-thistledown.com.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers AESGCM:ALL:!DH:!EXPORT:!RC4:+HIGH:!MEDIUM:!LOW:!aNULL:!eNULL; ssl_prefer_server_ciphers on; root /usr/share/nginx/html; index index.html index.htm; location / { root /usr/share/nginx/html; index index.html; } error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } }  Open specified ports (80, 443) and resolve my domain name to the server IP address.   Jekyll site building:  Create a new Jekyll site and add some posts. Build the site and output a static site to the nginx server\u0026rsquo;s root directory (in may case, /usr/share/nginx/html), located by the nginx configuration file.   Automated deployment:  Webhooks allow me to subscribe to certain events on GitHub.com. Every time I write a post or modify the blog locally and synchronize with the remote repository via git push, a HTTP POST payload will be sent to the webhook\u0026rsquo;s configured URL. With the help of github-webhook-handler, I can receive and verifying webhook requests from GitHub and execute the local script to pull the remote repositry and rebuild the site.    2. This New Hugo-based Blog As it claims, Hugo makes building websites fun and fast. Similarly, the website building process is divided into the following stages:\n Hugo site building:  Install hugo, create a new site and add a theme, with a blistering speed💨. Add my old posts. I was impressed by the built-in LiveReload, which saved me from repeatedly refreshing the page during development to see content changes, as I did with Jekyll.   GitHub Pages deployment:  Compared to my last site, I have to admit that GitHub Pages is a more time- and money-saving way to host a personal blog. Configuring a custom domain for my GitHub Pages site.   Add my own content:  Custom some CSS styles of the original theme. Add content and front matther to page templates. Updates:  Support $\\KaTeX$ (2022.03.29). Add a projects listing page and change the style of cover image (2022.04.02). Custom syntax highlighting style and make code block collapsible.      3. What I Talk About When I Talk About Blog The process of rebooting my blog not only helped me pick up some of the front-end knowledge I had forgotten, but also provided me with a new window of expression.\nToday, building such a site is no longer a complex project. From WordPress to Jekyll and now Hugo. I\u0026rsquo;m happy to embrace these new technologies that help us implement our ideas faster and more easily.\n","permalink":"https://jifan.tech/projects/blog/","summary":"Why and how did I build this blog.","title":"Blog"}]